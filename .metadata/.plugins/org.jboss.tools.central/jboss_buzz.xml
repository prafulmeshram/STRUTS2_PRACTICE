<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Enable Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform 7.3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ymljsPxTiCY/" /><category term="Containers" /><category term="DevOps" /><category term="Java" /><category term="Microservices" /><category term="CodeReady Studio" /><category term="jboss" /><category term="MicroProfile" /><category term="OpenTracing" /><author><name>Emmanuel Hugonnet</name></author><id>https://developers.redhat.com/blog/?p=722437</id><updated>2020-06-16T07:00:49Z</updated><published>2020-06-16T07:00:49Z</published><content type="html">&lt;p&gt;In this article, we show you how to install &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform (JBoss EAP)&lt;/a&gt; XP 1.0.0.GA and enable Eclipse MicroProfile support on JBoss EAP. Once you have MicroProfile support enabled, you can start using the quickstart examples or start developing your own application.&lt;/p&gt; &lt;p&gt;You can find a demo video at the end of this article.&lt;/p&gt; &lt;p&gt;&lt;span id="more-722437"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Installing JBoss EAP XP 1.0.0.GA&lt;/h2&gt; &lt;p&gt;To install &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/jbossnetwork/restricted/listSoftware.html?product=appplatform.xp&amp;#38;downloadType=distributions"&gt;JBoss EAP XP 1.0.0.GA&lt;/a&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li class="listitem"&gt; &lt;p class="simpara"&gt;Download the following software from the product download page:&lt;/p&gt; &lt;div class="itemizedlist"&gt; &lt;ul class="itemizedlist" type="disc"&gt; &lt;li class="listitem"&gt;JBoss EAP XP manager&lt;/li&gt; &lt;li class="listitem"&gt;JBoss EAP 7.3.1 GA patch&lt;/li&gt; &lt;li class="listitem"&gt;JBoss EAP XP 1.0&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li class="listitem"&gt; &lt;p class="simpara"&gt;Apply the JBoss EAP 7.3.1 GA patch:&lt;/p&gt; &lt;pre class="screen"&gt;$ patch apply /&lt;span class="emphasis"&gt;&lt;em&gt;DOWNLOAD/PATH&lt;/em&gt;&lt;/span&gt;/jboss-eap-7.3.1-patch.zip&lt;/pre&gt; &lt;/li&gt; &lt;li class="listitem"&gt; &lt;p class="simpara"&gt;Set up JBoss EAP XP manager using the following CLI command:&lt;/p&gt; &lt;pre class="screen"&gt;$ java -jar jboss-eap-xp-1.0.0.GA-CR1-manager.jar setup --jboss-home=/INSTALL_PATH/jboss-eap-7.3&lt;/pre&gt; &lt;/li&gt; &lt;li class="listitem"&gt; &lt;p class="simpara"&gt;Apply the JBoss EAP XP 1.0 patch using the following management command:&lt;/p&gt; &lt;pre class="screen"&gt;$ patch apply /&lt;span class="emphasis"&gt;&lt;em&gt;DOWNLOAD/PATH&lt;/em&gt;&lt;/span&gt;/jboss-eap-xp-1.0.0.GA-patch.zip&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Configure CodeReady Studio&lt;/h2&gt; &lt;p&gt;To enable Eclipse MicroProfile support on JBoss EAP, we first need to register a new runtime server for JBoss EAP XP 1.0.0 (which we just installed). For this, we will create a new JBoss EAP 7.3.0 server called Red Hat JBoss EAP 7.3 XP 1.0.&lt;/p&gt; &lt;p&gt;This server will use a newly created JBoss EAP 7.3 XP 1.0 Runtime that points to the newly installed runtime and uses the &lt;code&gt;standalone-microprofile.xml&lt;/code&gt; configuration file. Set up the &lt;strong&gt;New Server&lt;/strong&gt; dialog box as shown in Figure 1:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Select server type &lt;strong&gt;Red Hat JBoss Enterprise Application Platform 7.3&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Set &lt;strong&gt;Server&amp;#8217;s host name&lt;/strong&gt; to &lt;code&gt;localhost&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;In &lt;strong&gt;Server name&lt;/strong&gt;, enter &lt;code&gt;Red Hat JBoss EAP 7.3 XP 1.0&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_723207" style="width: 631px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-723207" class="wp-image-723207 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_1.png" alt="New Server dialog box with the specified options selected" width="621" height="590" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_1.png 621w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_1-300x285.png 300w" sizes="(max-width: 621px) 100vw, 621px" /&gt;&lt;p id="caption-attachment-723207" class="wp-caption-text"&gt;Figure 1: Define your new server.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the next dialog box, configure your new server as shown in Figure 2:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Set the &lt;strong&gt;Home Directory&lt;/strong&gt; if you don&amp;#8217;t want to use the default setting.&lt;/li&gt; &lt;li&gt;Make sure your &lt;strong&gt;Execution Environment&lt;/strong&gt; is set to &lt;strong&gt;JavaSE-1.8&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Change the settings for &lt;strong&gt;Server base directory&lt;/strong&gt; and &lt;strong&gt;Configuration file&lt;/strong&gt; if you don&amp;#8217;t want the defaults.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Finish&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_723197" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_2.png"&gt;&lt;img aria-describedby="caption-attachment-723197" class="wp-image-723197 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_2-1024x561.png" alt="New Server dialog box for configuring the JBoss Runtime" width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_2-1024x561.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_2-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_2-768x421.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/create_server_2.png 1077w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-723197" class="wp-caption-text"&gt;Figure 2: Configure your new server.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In order to use the &lt;strong&gt;microprofile-opentracing&lt;/strong&gt; quickstart (Figure 5) we need to set environment variables on our runtime. To do so, in the Red Hat JBoss EAP 7.3 XP 1.0 server &lt;strong&gt;Overview&lt;/strong&gt; dialog box shown in Figure 3, click &lt;strong&gt;Open launch configuration&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_723247" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_1.png"&gt;&lt;img aria-describedby="caption-attachment-723247" class="wp-image-723247 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_1-1024x672.png" alt="dialog box showing an overview of the server's settings" width="640" height="420" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_1-1024x672.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_1-300x197.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_1-768x504.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_1.png 1340w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-723247" class="wp-caption-text"&gt;Figure 3: Set environment variables from the server Overview dialog box.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In particular, you need to create three environment variables as shown in Figure 4:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;JAEGER_REPORTER_LOG_SPANS&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;JAEGER_SAMPLER_PARAM&lt;/code&gt; set to &lt;code&gt;1&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;JAEGER_SAMPLER_TYPE&lt;/code&gt; set to &lt;code&gt;const&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_723257" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_2.png"&gt;&lt;img aria-describedby="caption-attachment-723257" class="wp-image-723257" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_2.png" alt="dialog box showing the newly created environment variables" width="640" height="648" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_2.png 950w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_2-296x300.png 296w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/server_environment_2-768x778.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-723257" class="wp-caption-text"&gt;Figure 4: Configure your runtime&amp;#8217;s environment variables.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Use the quickstarts&lt;/h2&gt; &lt;p&gt;Select the Quickstart Parent &lt;code&gt;pom.xml&lt;/code&gt; to import it as shown in Figure 5, and you are ready to go.&lt;/p&gt; &lt;div id="attachment_723537" style="width: 648px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-723537" class="wp-image-723537 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/import_quickstarts.png" alt="Project Explorer with quickstart-parent selected." width="638" height="466" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/import_quickstarts.png 638w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/import_quickstarts-300x219.png 300w" sizes="(max-width: 638px) 100vw, 638px" /&gt;&lt;p id="caption-attachment-723537" class="wp-caption-text"&gt;Figure 5: Import quickstart-parent to turn on kickstarts.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;With the kickstarts turned on, you have simple examples that you can run and test on your installed server covering:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Eclipse MicroProfile Config&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Fault-tolerance&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Health&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile JWT&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Metrics&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile OpenAPI&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile OpenTracing&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile REST Client&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For more information about Eclipse MicroProfile take a look at &lt;a href="https://projects.eclipse.org/projects/technology.microprofile/releases/microprofile-3.3"&gt;the specifications&lt;/a&gt;, check out &lt;a target="_blank" rel="nofollow" href="https://start.microprofile.io/"&gt;MicroProfile Starter&lt;/a&gt;. If you prefer to watch a demo, check it out here:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/5sblsEHFQu4?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#38;linkname=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3%2F&amp;#038;title=Enable%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%207.3" data-a2a-url="https://developers.redhat.com/blog/2020/06/16/enable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3/" data-a2a-title="Enable Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform 7.3"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/16/enable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3/"&gt;Enable Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform 7.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ymljsPxTiCY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this article, we show you how to install Red Hat JBoss Enterprise Application Platform (JBoss EAP) XP 1.0.0.GA and enable Eclipse MicroProfile support on JBoss EAP. Once you have MicroProfile support enabled, you can start using the quickstart examples or start developing your own application. You can find a demo video at the end [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/16/enable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3/"&gt;Enable Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform 7.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">722437</post-id><dc:creator>Emmanuel Hugonnet</dc:creator><dc:date>2020-06-16T07:00:49Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/16/enable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3/</feedburner:origLink></entry><entry><title>Enterprise Kubernetes development with odo: The CLI tool for developers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gXynXpeiVwY/" /><category term="CI/CD" /><category term="Developer Tools" /><category term="Java" /><category term="Kubernetes" /><category term="Node.js" /><category term="Programming Languages" /><category term="application deployment" /><category term="command-line tool" /><category term="debug application" /><category term="kubernetes development" /><category term="openshift do" /><author><name>Jason Dudash</name></author><id>https://developers.redhat.com/blog/?p=726577</id><updated>2020-06-16T07:00:41Z</updated><published>2020-06-16T07:00:41Z</published><content type="html">&lt;p&gt;Kubernetes conversations rarely center the developer&amp;#8217;s perspective. As a result, doing our job in a k8s cluster often requires building complicated YAML resource files, writing custom shell scripts, and understanding the countless options that are available in &lt;code&gt;kubectl&lt;/code&gt; and &lt;code&gt;docker&lt;/code&gt; commands. On top of all of that, we have the learning curve of understanding Kubernetes terminology and using it the way that operations teams do.&lt;/p&gt; &lt;p&gt;To address these challenges, the Red Hat Developer Tools team created &lt;a href="https://developers.redhat.com/products/odo/overview"&gt;&lt;code&gt;odo&lt;/code&gt; (OpenShift Do)&lt;/a&gt;, a command-line interface (CLI) tool built for developers and designed to prioritize the things that developers care about. In this article, I will use a hands-on example to introduce you to the benefits of using &lt;code&gt;odo&lt;/code&gt; in conjunction with Kubernetes.&lt;/p&gt; &lt;h2&gt;Improving the developer workflow&lt;/h2&gt; &lt;p&gt;First, let&amp;#8217;s consider a typical workflow for a developer whose team has adopted &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;. The workflow starts with local development activities and finishes with &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt; deployed and code running in one or more Kubernetes clusters. To help visualize this flow, you can think of it in terms of an inner loop and an outer loop. The &lt;i&gt;inner loop&lt;/i&gt; consists of local coding, building, running, and testing the application—all activities that you, as a developer, can control. The &lt;i&gt;outer loop&lt;/i&gt; consists of the larger team processes that your code flows through on its way to the cluster: code reviews, integration tests, security and compliance, and so on. The inner loop could happen mostly on your laptop. The outer loop happens on shared servers and runs in containers, and is often automated with continuous integration/continuous delivery (CI/CD) pipelines. Usually, a code commit to source control is the transition point between the inner and outer loops. Figure 1 illustrates the interplay of these loops in a Kubernetes development process.&lt;/p&gt; &lt;div id="attachment_720877" style="width: 455px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/To-Staging.png"&gt;&lt;img aria-describedby="caption-attachment-720877" class="wp-image-720877 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/To-Staging.png" alt="A flow diagram of the inner and outer loops in a Kubernetes development process." width="445" height="439" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/To-Staging.png 445w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/To-Staging-300x296.png 300w" sizes="(max-width: 445px) 100vw, 445px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-720877" class="wp-caption-text"&gt;Figure 1. A flow diagram of the inner and outer loops in a Kubernetes development process.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Notice that, while you code, you are constantly iterating through various development activities: You code, build, deploy locally, and debug—and you keep going until you achieve a degree of feature completeness. At some point, you will be ready to transition from inner to outer, right? Not so quick.&lt;/p&gt; &lt;h3&gt;Deploying from the inner loop&lt;/h3&gt; &lt;p&gt;You might think that your job stops at local testing and a Git pull request (or a &lt;code&gt;git push&lt;/code&gt;)—but that&amp;#8217;s not usually the case. You will still need to ensure that your code functions correctly in containers, runs in the cluster, and plays nicely with other containerized components. Therefore, you will want some iterations of your inner loop to deploy and debug directly into the Kubernetes cluster.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s a list of steps you might typically follow to deploy from the inner loop:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Describe how to configure the OS for your container: &lt;ul&gt; &lt;li&gt;Write a Dockerfile to set up Linux.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Describe how to package your app into a container image: &lt;ul&gt; &lt;li&gt;Update the Dockerfile.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Create a container image: &lt;ul&gt; &lt;li&gt;Issue the commands &lt;code&gt;docker build&lt;/code&gt; and &lt;code&gt;docker tag&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Upload the container image to a registry: &lt;ul&gt; &lt;li&gt;Issue a &lt;code&gt;docker push.&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Write one or more Kubernetes or OpenShift resource files: &lt;ul&gt; &lt;li&gt;Write lots of YAML.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Deploy your app to the cluster: &lt;ul&gt; &lt;li&gt;Issue the command: &lt;code&gt;kubectl apply -f my_app.yaml&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Deploy other services to the cluster: &lt;ul&gt; &lt;li&gt;Issue the command: &lt;code&gt;kubectl apply -f svc*.yaml&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Write the config (or set &lt;code&gt;ENV&lt;/code&gt;) to allow apps to work together: &lt;ul&gt; &lt;li&gt;Issue a &lt;code&gt;kubectl create configmap&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Configure apps to work together correctly: &lt;ul&gt; &lt;li&gt;Issue a &lt;code&gt;kubectl apply -f my_configmap.yaml&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;That&amp;#8217;s a lot of steps!&lt;/p&gt; &lt;h3&gt;Enter, odo&lt;/h3&gt; &lt;p&gt;Red Hat OpenShift&amp;#8217;s &lt;code&gt;oc&lt;/code&gt; CLI tool can help make many of those steps easier; however, &lt;code&gt;oc&lt;/code&gt; is operations focused. Using it requires a deep understanding of Kubernetes and OpenShift concepts. Odo, on the other hand, was designed to be simple and concise:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Its syntax and design center concepts familiar to developers, such as projects, applications, and components.&lt;/li&gt; &lt;li&gt;It automates the creation of deployment configurations, build configurations, service routes, and other OpenShift elements.&lt;/li&gt; &lt;li&gt;It is designed for quick iterations—as an example, it detects changes to local code and deploys to the cluster automatically, giving developers instant feedback to validate changes in realtime.&lt;/li&gt; &lt;li&gt;It is completely client-based, so no server-side-component setup is required.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Odo also offers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Red Hat support for &lt;a href="https://developers.redhat.com/blog/category/node-js/"&gt;Node.js&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; components.&lt;/li&gt; &lt;li&gt;Compatibility with other languages such as Ruby, Perl, PHP, and Python.&lt;/li&gt; &lt;li&gt;Status updates for components and services on the cluster.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Odo works from any terminal on the Windows, macOS, and Linux operating systems, and it supports autocompletion for &lt;code&gt;bash&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt; command-line shells.&lt;/p&gt; &lt;p&gt;That&amp;#8217;s enough overview. Let&amp;#8217;s see &lt;code&gt;odo&lt;/code&gt; in action.&lt;/p&gt; &lt;h2&gt;Hands-on development with Odo&lt;/h2&gt; &lt;p&gt;If you want to follow along with this example, start by &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.4/cli_reference/openshift_developer_cli/installing-odo.html"&gt;downloading &lt;code&gt;odo&lt;/code&gt; for your platform of choice&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For macOS, the command is:&lt;/p&gt; &lt;pre&gt;&amp;#62; curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-darwin-amd64 -o /usr/local/bin/odo &amp;#38;&amp;#38; chmod +x /usr/local/bin/odo &lt;/pre&gt; &lt;p&gt;For Linux, it&amp;#8217;s:&lt;/p&gt; &lt;pre&gt;&amp;#62; curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-linux-amd64 -o /usr/local/bin/odo &amp;#38;&amp;#38; chmod +x /usr/local/bin/odo &lt;/pre&gt; &lt;p&gt;Next, &lt;a target="_blank" rel="nofollow" href="https://github.com/RedHatGov/openshift-workshops.git"&gt;clone the example source code&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#62; git clone https://github.com/RedHatGov/openshift-workshops.git &amp;#62; cd openshift-workshops/dc-metro-map &lt;/pre&gt; &lt;p&gt;If you aren&amp;#8217;t already logged in to your cluster with &lt;code&gt;oc&lt;/code&gt;, run this and enter your login info:&lt;/p&gt; &lt;pre&gt;&amp;#62; odo login https://api.yourcluster.com:6443 &lt;/pre&gt; &lt;p&gt;Alternatively, you could use the following link to get a token-based login (note that you must update the URL with your cluster&amp;#8217;s domain name): &lt;code&gt;https://oauth-openshift.apps.yourcluster.com/oauth/token/display&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We now have a setup for a sample Node.js application. In the next sections, I&amp;#8217;ll show you how to use &lt;code&gt;odo&lt;/code&gt; to deploy the app to a Kubernetes cluster; configure and connect the app to other services; and update an environment variable and verify the changes in a web browser. I&amp;#8217;ll conclude by showing you how to do a simple code change and quickly iterate through the development process before propagating your local code back into the Kubernetes cluster.&lt;/p&gt; &lt;h3&gt;Part 1: Deploy the app&lt;/h3&gt; &lt;p&gt;The first thing you&amp;#8217;ll do is set up a new project and deploy it on a Kubernetes cluster.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a project that only you can work in by entering a command similar to the one below: &lt;pre&gt;&amp;#62; odo project create jasons-odo &lt;/pre&gt; &lt;p&gt;You should see output similar to mine below:&lt;/p&gt; &lt;pre&gt;✓ Project 'jasons-odo' is ready for use ✓ New project created and now using project: jasons-odo &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Create a Node.js component for the new project: &lt;pre&gt;&amp;#62; odo create nodejs &lt;/pre&gt; &lt;p&gt;The output should look something like this:&lt;/p&gt; &lt;pre&gt;✓ Validating component [61ms] Please use `odo push` command to create the component with source deployed &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Push the changes—in this case, a new component and the example application code—to the cluster: &lt;pre&gt;&amp;#62; odo push &lt;/pre&gt; &lt;p&gt;You should see something like this:&lt;/p&gt; &lt;pre&gt;Validation ✓ Checking component [116ms] Configuration changes ✓ Initializing component ✓ Creating component [336ms] Pushing to component nodejs-dc-metro-map-zvff of type local ✓ Checking files for pushing [2ms] ✓ Waiting for component to start [1m] ✓ Syncing files to the component [7s] ✓ Building component [32s] ✓ Changes successfully pushed to component &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The code is now running in a container on the cluster. But we also want to create a URL route into the code so that we can view the running application in a web browser. Next steps:&lt;/p&gt; &lt;ol start="4"&gt; &lt;li&gt;Expose an HTTP route into your Node.js app: &lt;pre&gt;&amp;#62; odo url create --port 8080&lt;/pre&gt; &lt;p&gt;Check the output:&lt;/p&gt; &lt;pre&gt;✓ URL nodejs-dc-metro-map-zvff-8080 created for component: nodejs-dc-metro-map-zvff To create URL on the OpenShift Cluster, please use `odo push` &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Push the new URL change to the cluster: &lt;pre&gt;&amp;#62; odo push &lt;/pre&gt; &lt;p&gt;Check the output:&lt;/p&gt; &lt;pre&gt;Validation ✓ Checking component [88ms] Configuration changes ✓ Retrieving component data [107ms] ✓ Applying configuration [107ms] Applying URL changes ✓ URL nodejs-dc-metro-map-zvff-8080: http://nodejs-dc-metro-map-zvff-8080-app-jasons-odo.apps.yourcluster.com created Pushing to component nodejs-dc-metro-map-zvff of type local ✓ Checking file changes for pushing [7ms] ✓ No file changes detected, skipping build. Use the '-f' flag to force the build. &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;To verify that the deployment has worked, locate the URL in the command output just shown (or run &lt;code&gt;odo url list&lt;/code&gt;) and try opening it in your web browser. You should see something like the map in Figure 2.&lt;/p&gt; &lt;div id="attachment_720847" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-1.png"&gt;&lt;img aria-describedby="caption-attachment-720847" class="wp-image-720847 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-1-1024x860.png" alt="A map of transit stops in Washington DC's Federal Triangle." width="640" height="538" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-1-1024x860.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-1-300x252.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-1-768x645.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-1.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-720847" class="wp-caption-text"&gt;Figure 2. A map of transit stops in Washington D.C.&amp;#8217;s Federal Triangle.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Part 2: Configure and connect the app to other services&lt;/h3&gt; &lt;p&gt;Next, you&amp;#8217;ll use &lt;code&gt;odo&lt;/code&gt; to add a database dependency to your Node.js app. For this to work, your cluster will need to have both OpenShift &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.4/applications/service_brokers/installing-service-catalog.html"&gt; Service Catalog&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.4/applications/service_brokers/installing-template-service-broker.html"&gt;Template Service Broker&lt;/a&gt; installed.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create the database and pass-in the defaults for config variables: &lt;pre&gt;&amp;#62; odo service create mongodb-persistent --plan default --wait \ -p DATABASE_SERVICE_NAME=mongodb -p MEMORY_LIMIT=512Mi \ -p MONGODB_DATABASE=sampledb -p VOLUME_CAPACITY=1Gi &lt;/pre&gt; &lt;p&gt;Here&amp;#8217;s the output:&lt;/p&gt; &lt;pre&gt;Deploying service mongodb-persistent of type: mongodb-persistent ✓ Deploying service [55ms] ✓ Waiting for service to come up [3m] ✓ Service 'mongodb-persistent' is ready for use &lt;/pre&gt; &lt;p&gt;Optionally, link &lt;code&gt;mongodb-persistent&lt;/code&gt; to your component by running: &lt;code&gt;odo link&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Provide your Node.js app with the database credentials and other secrets needed to configure and connect to the database: &lt;pre&gt;&amp;#62; odo link mongodb-persistent &lt;/pre&gt; &lt;p&gt;You should see something like the following output:&lt;/p&gt; &lt;pre&gt;✓ Service mongodb-persistent has been successfully linked to the component nodejs-dc-metro-map-zvff The below secret environment variables were added to the 'nodejs-dc-metro-map-zvff' component: admin_password database_name password uri username You can now access the environment variables from within the component pod, for example: $uri is now available as a variable within component nodejs-dc-metro-map-zvff &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;Part 3: Update the environment variables&lt;/h3&gt; &lt;p&gt;Let&amp;#8217;s say you need to update some &lt;code&gt;env vars&lt;/code&gt; for your containerized Node.js app. Doing that with &lt;code&gt;odo&lt;/code&gt; is really straightforward.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Tell &lt;code&gt;odo&lt;/code&gt; what &lt;code&gt;env var&lt;/code&gt; to add or update: &lt;pre&gt;&amp;#62; odo config set --env BEERME=true &lt;/pre&gt; &lt;p&gt;You should see something like the following output:&lt;/p&gt; &lt;pre&gt; ✓ Environment variables were successfully updated Run `odo push --config` command to apply changes to the cluster. &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Push the changes with the new &lt;code&gt;env var&lt;/code&gt; to the cluster: &lt;pre&gt;&amp;#62; odo push --config &lt;/pre&gt; &lt;p&gt;You should see something like this:&lt;/p&gt; &lt;pre&gt;Validation ✓ Checking component [84ms] Configuration changes ✓ Retrieving component data [96ms] ✓ Applying configuration [40s] Applying URL changes ✓ URL nodejs-dc-metro-map-zvff-8080 already exists &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Now refresh the page in your web browser. You&amp;#8217;ll see that the new &lt;code&gt;env&lt;/code&gt; has taken effect. Your map icons should now look like pint glasses, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_720857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-2.png"&gt;&lt;img aria-describedby="caption-attachment-720857" class="wp-image-720857 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-2-1024x938.png" alt="The updated map shows the effect of changing the environment variable." width="640" height="586" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-2-1024x938.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-2-300x275.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-2-768x703.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-2.png 1352w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-720857" class="wp-caption-text"&gt;Figure 3. The updated map icons verify that changing the environment variable worked.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Part 4: Iterate the inner loop&lt;/h3&gt; &lt;p&gt;In this last part, I&amp;#8217;ll show you how to do a simple code change with &lt;code&gt;odo&lt;/code&gt;. I&amp;#8217;ll also demonstrate how iterating on your inner loop easily propagates local code into the cluster deployment.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Edit the local file &lt;code&gt;public/assets/stations.geojson&lt;/code&gt; to add a new bus stop. Append it to the bottom of the file, right after Ronald Reagan Washington National Airport: &lt;pre&gt;&amp;#62; vim public/assets/stations.geojson { "type": "Feature", "properties": { "name": "Presidential Metro Stop", "marker-color": "#ffd700", "marker-symbol": "rail-metro", "line": "blue" }, "geometry": { "type": "Point", "coordinates": [ -77.0365, 38.8977 ] } } &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Push changes to the cluster: &lt;pre&gt;&amp;#62; odo push&lt;/pre&gt; &lt;p&gt;You should see the following output:&lt;/p&gt; &lt;pre&gt;Validation ✓ Checking component [86ms] Configuration changes ✓ Retrieving component data [96ms] ✓ Applying configuration [114ms] Applying URL changes ✓ URL nodejs-dc-metro-map-zvff-8080 already exists Pushing to component nodejs-dc-metro-map-zvff of type local ✓ Checking file changes for pushing [3ms] ✓ Waiting for component to start [23ms] ✓ Syncing files to the component [1s] ✓ Building component [3s] ✓ Changes successfully pushed to component &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Now, refresh the web page. You should see that there&amp;#8217;s a new transit stop for the White House, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_720867" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-3.png"&gt;&lt;img aria-describedby="caption-attachment-720867" class="wp-image-720867 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-3-1024x751.png" alt="An updated map with a new bus icon located at the White House." width="640" height="469" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-3-1024x751.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-3-300x220.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-3-768x563.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/Map-3.png 1584w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-720867" class="wp-caption-text"&gt;Figure 4. The updated map shows that code changes have been successfully pushed to the deployed cluster.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, I showed you how to use &lt;code&gt;odo&lt;/code&gt; for a variety of day-to-day development activities (what I call the inner loop of a Kubernetes-based development process). I also showed you how to deploy and debug iterations of your inner loop directly into the Kubernetes cluster.&lt;/p&gt; &lt;p&gt;We completed all of the tasks required to develop and deploy the example application without writing any YAML, without &lt;code&gt;bash&lt;/code&gt; scripts, and without needing to understand the deep concepts of Kubernetes operations. Instead, we used the CLI and just a handful of commands—&lt;code&gt;odo&lt;/code&gt;, &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;push&lt;/code&gt;, &lt;code&gt;service&lt;/code&gt;, &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;config&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Odo can do a few things I didn&amp;#8217;t cover in this article. See the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.4/cli_reference/openshift_developer_cli/understanding-odo.html"&gt;official odo documentation&lt;/a&gt; to learn more about its full capabilities.&lt;/p&gt; &lt;p&gt;Also, if you liked the concepts in this article but really don&amp;#8217;t like using a CLI, Red Hat has you covered. We&amp;#8217;ve embedded &lt;code&gt;odo&lt;/code&gt; into a &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-openshift-connector"&gt;VS Code plugin&lt;/a&gt; and a &lt;a target="_blank" rel="nofollow" href="https://plugins.jetbrains.com/plugin/12030-openshift-connector-by-red-hat"&gt;JetBrains plugin&lt;/a&gt;, so that you can get the same capability directly in an IDE.&lt;/p&gt; &lt;p&gt;Odo is just one of the awesome tools that Red Hat has been working on to make it easier for developers to build modern applications with open source software. Stay tuned for more articles introducing these tools that are tailored just for developers.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#38;linkname=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F16%2Fenterprise-kubernetes-development-with-odo-the-cli-tool-for-developers%2F&amp;#038;title=Enterprise%20Kubernetes%20development%20with%20odo%3A%20The%20CLI%20tool%20for%20developers" data-a2a-url="https://developers.redhat.com/blog/2020/06/16/enterprise-kubernetes-development-with-odo-the-cli-tool-for-developers/" data-a2a-title="Enterprise Kubernetes development with odo: The CLI tool for developers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/16/enterprise-kubernetes-development-with-odo-the-cli-tool-for-developers/"&gt;Enterprise Kubernetes development with odo: The CLI tool for developers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gXynXpeiVwY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Kubernetes conversations rarely center the developer&amp;#8217;s perspective. As a result, doing our job in a k8s cluster often requires building complicated YAML resource files, writing custom shell scripts, and understanding the countless options that are available in kubectl and docker commands. On top of all of that, we have the learning curve of understanding Kubernetes [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/16/enterprise-kubernetes-development-with-odo-the-cli-tool-for-developers/"&gt;Enterprise Kubernetes development with odo: The CLI tool for developers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">726577</post-id><dc:creator>Jason Dudash</dc:creator><dc:date>2020-06-16T07:00:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/16/enterprise-kubernetes-development-with-odo-the-cli-tool-for-developers/</feedburner:origLink></entry><entry><title>Cloud-native development - A deployment blueprint</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XvrVzLAP-BQ/cloud-native-development-a-deployment-blueprint.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-cloud_native_development_a_deployment_blueprint</id><updated>2020-06-16T08:18:46Z</updated><published>2020-06-16T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-7Y4CiiYTYj4/Xr50P1i2xAI/AAAAAAAAxIw/h2j8QBiLk20JYX-6dJkeJVOv_Ud9XvzdQCNcBGAsYHQ/s1600/cloud-native-development-ld.png" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;"&gt;&lt;img alt="cloud-native development" border="1" data-original-height="900" data-original-width="1600" height="180" src="https://1.bp.blogspot.com/-7Y4CiiYTYj4/Xr50P1i2xAI/AAAAAAAAxIw/h2j8QBiLk20JYX-6dJkeJVOv_Ud9XvzdQCNcBGAsYHQ/s320/cloud-native-development-ld.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="font-size: 12.8px; text-align: center;"&gt;Part 5 - A deployment blueprint&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;The previous articles were &lt;a href="https://www.schabell.org/2020/05/cloud-native-development-a-blueprint.html" target="_blank"&gt;introducing the foundations&lt;/a&gt; of a blueprint&amp;nbsp;for cloud-native development, &lt;a href="https://www.schabell.org/2020/05/cloud-native-development-common-architectural-elements.html" target="_blank"&gt;exploring a logical diagram&lt;/a&gt;, and diving into the first use cases with&amp;nbsp;cloud-native &lt;a href="https://www.schabell.org/2020/06/cloud-native-development-on-local-containers.html" target="_blank"&gt;development on local&lt;/a&gt; and &lt;a href="https://www.schabell.org/2020/06/cloud-native-development-on-remote-containers.html" target="_blank"&gt;remote containers&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;In this article we're continuing on with example use cases within the architectural blueprint. Descriptions are provided to guide you with aligning the landscape your organization works with every day.&lt;br /&gt;&lt;br /&gt;These details should help you understand both what the elements contain and how they might align and how their functionalities are grouped. Let's look at the use case where developers are leveraging a remote container platform for their cloud-native development environments and see how that's mapping to a productive working architecture for deploying their solutions.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;We'll be exploring the use case detailing deployments from a developers local machines to development, testing, and finally production environments.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Deployments&lt;/h3&gt;&lt;div&gt;This example starts with a cloud-native developer working on their local machines, shown here simplified as workstation tooling. Pushing their code solutions [1], using their container tooling to initiate a build in their continuous integration and development workflow (CI/CD).&lt;br /&gt;&lt;br /&gt;(*Note: all numbered steps found in the below image are presented in the text as [#], so step one with label one is shown as [1] in the deployment storyline as it appears.)&lt;br /&gt;&lt;br /&gt;In this blueprint, the tooling is focused on working with the OpenShift Container Platform so you see an&amp;nbsp;&lt;i&gt;OpenShift client&lt;/i&gt;&amp;nbsp;is used to trigger an initial build in our CI/CD OpenShift platform. This occurs when the developer is satisfied with their code. Triggering a build and testing request to the CI/CD platform shown here as being hosted on an OpenShift Container Platform cluster:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;using git hooks, triggering a code push when it's committed to the local code repository&lt;/li&gt;&lt;li&gt;using Maven plugins, triggering a push to the development infrastructure when activated&lt;/li&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: right; text-align: right;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-JJMZkRC0oBQ/Xuhz6szkdbI/AAAAAAAAxPM/5U66DEQ4Www7Y5bjqpfwrINTkNhDkuS5gCNcBGAsYHQ/s1600/cloud-native-development-deployment-sd.png" imageanchor="1" style="clear: right; margin-bottom: 1em; margin-left: auto; margin-right: auto;"&gt;&lt;img alt="cloud-native development" border="0" data-original-height="900" data-original-width="1600" height="180" src="https://1.bp.blogspot.com/-JJMZkRC0oBQ/Xuhz6szkdbI/AAAAAAAAxPM/5U66DEQ4Www7Y5bjqpfwrINTkNhDkuS5gCNcBGAsYHQ/s320/cloud-native-development-deployment-sd.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Deployment blueprint with numbered labels&lt;br /&gt;as workloads are built, tagged, and deployed.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;li&gt;using&amp;nbsp;&lt;i&gt;oc client&lt;/i&gt;&amp;nbsp;container tooling (featured in the diagram)&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;Development teams are free to use the method that best suits their own needs when pushing their code to&amp;nbsp; their CI/CD platform.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;CI/CD infrastructure&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;The pushed code from the developers local working environment is picked up by the CI/CD platform, in this case most often was a Jenkins-based platform. Here we see the CI/CD platform uses a source-to-image workflow [2] to build the container image, test the image, and place it [3] in the transient image registry. At this point it has been tagged as &lt;i&gt;appImage:dev&lt;/i&gt;&amp;nbsp;and is pushed to the OpenShift cluster hosting the enterprise image registry managed with Quay [4].&lt;br /&gt;&lt;br /&gt;For this blueprint we've kept the enterprise image&amp;nbsp; registry storyline simple, just a single Quay instance, but in reality it's important to have stages for security testing, segregation of development and untested images, and to only allow fully certified images to be put into production. In our next article we'll expand on these more advanced deployments.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;Development infrastructure&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;The development infrastructure image registry is loaded with a copy of the&amp;nbsp;&lt;i&gt;appImage:dev&lt;/i&gt;&amp;nbsp;tagged container image [5], which then deploys [6] the &lt;i&gt;application&lt;/i&gt;&amp;nbsp;and m&lt;i&gt;icroservices&lt;/i&gt;&amp;nbsp;associated with our workload. The development infrastructure is contained in it's own OpenShift cluster for further testing and validation of the developed application and microservices.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once the development testing has been satisfied, the&amp;nbsp;&lt;i&gt;appImage&lt;/i&gt;&amp;nbsp;is tagged as&amp;nbsp;&lt;i&gt;appImage:test&lt;/i&gt;&amp;nbsp;and pushed from the CI/CD platform [7] to the Quay enterprise image registry.&lt;br /&gt;&lt;br /&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;Test infrastructure&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;All images tagged as &lt;i&gt;test&lt;/i&gt; are pushed from the Quay enterprise image registry to the test infrastructure [8] into the test OpenShift cluster image registry. The&amp;nbsp;&lt;i&gt;appImage:test&lt;/i&gt;&amp;nbsp;is used for deploying [9] the containers with the&amp;nbsp;&lt;i&gt;application&lt;/i&gt;&amp;nbsp;and&amp;nbsp;&lt;i&gt;microservices&lt;/i&gt;&amp;nbsp;as needed. At this point the testing cycle starts again with new test infrastructure data and requirements on the road to a production deployment.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once the testing has been satisfied, the &lt;i&gt;appImage&lt;/i&gt;&amp;nbsp;is tagged as &lt;i&gt;appImage:prod&lt;/i&gt;&amp;nbsp;and pushed from the CI/CD platform [10] to the Quay enterprise image registry.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;Production infrastructure&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;All images tagged as &lt;i&gt;prod&lt;/i&gt; are pushed from the Quay enterprise image registry to the production infrastructure [11] into the production OpenShift cluster image registry. The&amp;nbsp;&lt;i&gt;appImage:prod&lt;/i&gt;&amp;nbsp;is used for deploying [12] the containers with the&amp;nbsp;&lt;i&gt;application&lt;/i&gt;&amp;nbsp;and&amp;nbsp;&lt;i&gt;microservices&lt;/i&gt;&amp;nbsp;as needed. At this point the workload is live for use in the production environment.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This use case example features the deployment architecture for your workloads using cloud-native development in your organization. It's featuring a blueprint for mapping your cloud-native development process for deploying the developer solution through to your production infrastructure.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;h3&gt;Exploring the diagrams&lt;/h3&gt;&lt;div&gt;As mentioned in the introduction to this series, we've pulled together an&amp;nbsp;&lt;a href="https://gitlab.com/redhatdemocentral/portfolio-architecture-examples" target="_blank"&gt;examples repository&lt;/a&gt;&amp;nbsp;for all our architecture blueprint diagrams. The&amp;nbsp;&lt;a href="https://gitlab.com/redhatdemocentral/portfolio-architecture-examples" target="_blank"&gt;Portfolio Architecture Examples&lt;/a&gt;&amp;nbsp;repository makes it possible to collect and share individual images from each diagram element as well as the entire project as a whole.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://1.bp.blogspot.com/-dRBXuaZt5t0/XsuO-04T-9I/AAAAAAAAxK4/lXES7oKvrwEJjgtKcvJyJqwK3v0Ey65lgCNcBGAsYHQ/s1600/Screenshot%2B2020-05-25%2Bat%2B11.24.53.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="cloud-native development" border="1" data-original-height="303" data-original-width="1219" height="98" src="https://1.bp.blogspot.com/-dRBXuaZt5t0/XsuO-04T-9I/AAAAAAAAxK4/lXES7oKvrwEJjgtKcvJyJqwK3v0Ey65lgCNcBGAsYHQ/s400/Screenshot%2B2020-05-25%2Bat%2B11.24.53.png" title="" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;To access the diagram covered in this article, you scroll down to the file listings on the main page, you can locate a schematic diagram as shown in the figure here.&lt;br /&gt;&lt;br /&gt;This is the collection for the schematic diagrams associated with cloud-native development:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;in this case it's a single image you can click to view&lt;/li&gt;&lt;li&gt;a project file you can download to your local machine using the&amp;nbsp;&lt;i&gt;Download Diagram&lt;/i&gt;&amp;nbsp;link&lt;/li&gt;&lt;li&gt;a&amp;nbsp;&lt;i&gt;Load Diagram&lt;/i&gt;&amp;nbsp;link that you can click to automatically open the project diagrams in the diagram tooling used in this blueprint&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;Give it a try and feel free to explore the collection of logical, schematic, detailed, solution, and community diagrams. This should allow you to get started much quicker than from scratch if you can kick-start a project with existing diagrams.&lt;br /&gt;&lt;br /&gt;Should you design your own diagrams, please contribute the project file (ending in .drawio) by raising an issue with the file attached. We'd love to continue collecting these projects for others to use.&lt;br /&gt;&lt;br /&gt;Finally, there is a free online&amp;nbsp;&lt;a href="https://redhatdemocentral.gitlab.io/portfolio-architecture-workshops" target="_blank"&gt;beginners guide workshop&lt;/a&gt;&amp;nbsp;available focused on using the diagram tooling, please explore to learn tips and tricks from the experts.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3&gt;What's next&lt;/h3&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;An overview of the series on the cloud-native development portfolio architecture blueprint can be found here:&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/05/cloud-native-development-a-blueprint.html" target="_blank"&gt;A blueprint&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/05/cloud-native-development-common-architectural-elements.html" target="_blank"&gt;Common architectural elements&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/06/cloud-native-development-on-local-containers.html" target="_blank"&gt;Cloud-native development on local containers&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/06/cloud-native-development-on-remote-containers.html" target="_blank"&gt;Cloud-native development on remote containers&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/06/cloud-native-development-a-deployment-blueprint.html" target="_blank"&gt;Cloud-native deployments&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Cloud-native advanced deployments&lt;/li&gt;&lt;/ol&gt;Catch up on any articles you missed by following one of the links above. Next in this series, taking a look at cloud-native advanced deployments.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=wP0JnuQHsBU:RXPsXVKnFxo:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=wP0JnuQHsBU:RXPsXVKnFxo:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=wP0JnuQHsBU:RXPsXVKnFxo:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=wP0JnuQHsBU:RXPsXVKnFxo:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=wP0JnuQHsBU:RXPsXVKnFxo:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/wP0JnuQHsBU" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XvrVzLAP-BQ" height="1" width="1" alt=""/&gt;</content><summary>Part 5 - A deployment blueprintThe previous articles were introducing the foundations of a blueprint for cloud-native development, exploring a logical diagram, and diving into the first use cases with cloud-native development on local and remote containers. In this article we're continuing on with example use cases within the architectural blueprint. Descriptions are provided to guide you with ali...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-06-16T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/wP0JnuQHsBU/cloud-native-development-a-deployment-blueprint.html</feedburner:origLink></entry><entry><title>Infinispan 11.0.0.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/HIk81kizi4A/" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>Tristan Tarrant</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_11_0_0_final</id><updated>2020-06-16T07:11:48Z</updated><published>2020-06-15T12:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Dear Infinispan community,&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We’re proud to announce the release of Infinispan 11. In the tradition of assigning beer codenames to our releases, we decided that "Corona Extra" would be a significant representation of the period during which most of the development has happened. We hope that you, your families and friends have not been impacted by the pandemic.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_but_didnt_you_release_10_x_not_long_ago"&gt;&lt;a class="anchor" href="#_but_didnt_you_release_10_x_not_long_ago" /&gt;But didn’t you release 10.x not long ago ?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Indeed, but version numbers are just that: numbers. We are still continuing our near-quarterly releases, but, from now on, these will be identified by major version numbers.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_so_whats_new_in_infinispan_11"&gt;&lt;a class="anchor" href="#_so_whats_new_in_infinispan_11" /&gt;So, what’s new in Infinispan 11 ?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As usual we added new features, improved existing ones and prepared the groundwork for upcoming features.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_conflict_detection_and_resolution_for_asynchronous_cross_site_replication"&gt;&lt;a class="anchor" href="#_conflict_detection_and_resolution_for_asynchronous_cross_site_replication" /&gt;Conflict detection and resolution for Asynchronous Cross-Site Replication&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Cross-site replication is one of our most used features, as it enables a number of very useful use-cases such as geographical load distribution, zero-downtime disaster recovery and follow-the-sun data centers.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In this release we completely overhauled the way we implement asynchronous cross-site replication by introducing conflict resolution, based on vector clocks, as well as multiple site masters to increase throughput and reliability. This means that you can have multiple active sites safely replicating data between each other.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_server_security_overhaul"&gt;&lt;a class="anchor" href="#_server_security_overhaul" /&gt;Server security overhaul&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Infinispan Server’s security, while very powerful, was also tricky to set up because of the configuration complexity. Since we wanted to make the &lt;a href="//infinispan.org/blog/2020/06/04/server-secure-by-default/"&gt;server secure by default&lt;/a&gt;, we put a lot of work in simplifying the configuration and removing all of the boilerplate. Additionally, if you are securing the server with &lt;a href="https://keycloak.org"&gt;Keycloak&lt;/a&gt;, accessing the console will correctly obtain credentials through the realm login page.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_non_blocking_internals"&gt;&lt;a class="anchor" href="#_non_blocking_internals" /&gt;Non-blocking internals&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Our quest to make better use of the available hardware resources in all deployment models (bare-metal, containerized, virtualized) continues as we’ve now consolidated a lot of thread-pools into just two: non-blocking and blocking. Most of the code now makes use of the non-blocking pool. Paths which may block, such as certain persistent stores, use the blocking pool so that they don’t hold up work that may be processed without blocking. This release also includes a new non-blocking Store SPI, so that you can take advantage of stores with real non-blocking I/O.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_clustering"&gt;&lt;a class="anchor" href="#_clustering" /&gt;Clustering&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As Infinispan is participating in &lt;a href="https://cloudbutton.eu/"&gt;CloudButton&lt;/a&gt;, a Serverless Data Analytics Platform which is part of the &lt;a href="https://ec.europa.eu/programmes/horizon2020/"&gt;European Union’s Horizon 2020 research and innovation programme&lt;/a&gt;, we have introduced a new optional feature which allows scaling by adding new nodes to a cluster without state-transfer. This means that you can add capacity with zero-impact to your operations. Obviously this comes at the cost of reduced resilience in case of failures, but, for scenarios where high availability is not required, this gives you a highly scalable in-memory storage solution.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If high availability is your thing, the rebalancing algorithm which decides how segments (our subdivision of the data space) are mapped to nodes has been overhauled to be much more accurate and fairer.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_queryindexing"&gt;&lt;a class="anchor" href="#_queryindexing" /&gt;Query/Indexing&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Querying and indexing will be the major focus in Infinispan 12 (with the long awaited upgrade to &lt;a href="https://hibernate.org/search/"&gt;Hibernate Search 6&lt;/a&gt; and &lt;a href="https://lucene.apache.org/"&gt;Lucene 8&lt;/a&gt;). In preparation for that, &lt;strong&gt;a lot&lt;/strong&gt; of work has gone into deprecations, usability, clean ups and documentation.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_hot_rod_client_improvements"&gt;&lt;a class="anchor" href="#_hot_rod_client_improvements" /&gt;Hot Rod Client improvements&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Many usability changes have been added to our Java Hot Rod client:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;a Hot Rod URI as a compact way to configure a connection&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;automatic creation of caches on demand using supplied configurations/templates with support for wildcards&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;improved iteration of entries by concurrently splitting work across segments/nodes&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_other_server_changes"&gt;&lt;a class="anchor" href="#_other_server_changes" /&gt;Other Server changes&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you are using the JDBC cache store to persist your cache entries to a database, Infinispan Server now restores the ability to create shared datasources which was lost when we abandoned the WildFly base.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_cli"&gt;&lt;a class="anchor" href="#_cli" /&gt;CLI&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The CLI received a number of new features such as logging manipulation, obtaining sever reports and user management, superseding the &lt;code&gt;user-tool&lt;/code&gt; script.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;a class="image" href="//infinispan.org/blog/img/ispn110cli.png"&gt;&lt;img src="//infinispan.org/blog/thumb/ispn101welcome.png" alt="CLI" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_console"&gt;&lt;a class="anchor" href="#_console" /&gt;Console&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Our console overhaul, which started in 10, continues with lots of new features, integrations and polishing. Highlights are:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;entry creation dialog box&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;querying&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;KeyCloak integration&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;a class="image" href="//infinispan.org/blog/img/ispn110console.png"&gt;&lt;img src="//infinispan.org/blog/thumb/ispn110console.png" alt="onsole" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_clouds_containers_and_operators"&gt;&lt;a class="anchor" href="#_clouds_containers_and_operators" /&gt;Clouds, containers and operators&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Our Infinispan Server image is now based on &lt;code&gt;ubi-minimal:8.2&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;And thanks to our friends over at &lt;a href="https://quarkus.io"&gt;Quarkus&lt;/a&gt;, Infinispan Server is now also available as a native image built using &lt;a href="https://graalvm.org"&gt;GraalVM&lt;/a&gt;. This image is available on Quay.io and Docker Hub.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Kubernetes Operator adds a new Cache Custom Resource and the ability to expose services via Ingress and Routes.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_documentation"&gt;&lt;a class="anchor" href="#_documentation" /&gt;Documentation&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Documentation has also received a lot of love in all areas:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Added procedural content for rolling upgrades, Cache CR with the Operator, server patching, misc CLI commands, using RemoteCacheConfigurationBuilder.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Procedural content for different upgrade and migration tasks included in Upgrade Guide.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Operator and Spring Boot Starter guides now provide stable and development versions from the index page.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Updated index.html and throughout documentation to improve high-level context and aid retrievability.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Getting Started content updated and streamlined.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Applied several modifications, additions, and removals to documentation via community feedback.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_whats_next"&gt;&lt;a class="anchor" href="#_whats_next" /&gt;What’s next ?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As briefly mentioned above, Infinispan 12 will be our next release, scheduled for this autumn. We will be working on query/index improvements, backup/restore capabilities as well as the usual load of improvements, clean-ups across the board. We will keep you posted with development release and blogs about upcoming highlights. If you’d like to contribute, just get in touch.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_get_it_use_it_ask_us"&gt;&lt;a class="anchor" href="#_get_it_use_it_ask_us" /&gt;Get it, Use it, Ask us!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please &lt;a href="https://infinispan.org/download/"&gt;download&lt;/a&gt;, &lt;a href="https://issues.jboss.org/projects/ISPN"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/"&gt;chat with us&lt;/a&gt;, ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/HIk81kizi4A" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan community, We’re proud to announce the release of Infinispan 11. In the tradition of assigning beer codenames to our releases, we decided that "Corona Extra" would be a significant representation of the period during which most of the development has happened. We hope that you, your families and friends have not been impacted by the pandemic. But didn’t you release 10.x not long ag...</summary><dc:creator>Tristan Tarrant</dc:creator><dc:date>2020-06-15T12:00:00Z</dc:date><feedburner:origLink>http://infinispan.org/blog/2020/06/15/infinispan-11/</feedburner:origLink></entry><entry><title>Jakarta EE: Multitenancy with JPA on WildFly, Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7zZq2y1lyIQ/" /><category term="Containers" /><category term="DevOps" /><category term="Java" /><category term="Hibernate JPA" /><category term="Jakarta EE" /><category term="multi-tenancy" /><category term="WildFly" /><author><name>rhsilva</name></author><id>https://developers.redhat.com/blog/?p=720037</id><updated>2020-06-15T07:00:45Z</updated><published>2020-06-15T07:00:45Z</published><content type="html">&lt;p&gt;In this two-part series, I demonstrate two approaches to multitenancy with the &lt;a target="_blank" rel="nofollow" href="https://projects.eclipse.org/projects/ee4j.jpa"&gt;Jakarta Persistence API (JPA)&lt;/a&gt; running on &lt;a target="_blank" rel="nofollow" href="https://wildfly.org"&gt;WildFly&lt;/a&gt;. In the first half of this series, you will learn how to implement multitenancy using a database. In the second half, I will introduce you to multitenancy using a schema. I based both examples on JPA and &lt;a target="_blank" rel="nofollow" href="http://hibernate.org"&gt;Hibernate&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Because I have focused on implementation examples, I won&amp;#8217;t go deeply into the details of multitenancy, though I will start with a brief overview. Note, too, that I assume you are familiar with Java persistence using JPA and Hibernate.&lt;/p&gt; &lt;h2&gt;Multitenancy architecture&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.jboss.org/hibernate/orm/4.1/devguide/en-US/html/ch16.html"&gt;Multitenancy&lt;/a&gt; is an architecture that permits a single application to serve multiple tenants, also known as clients. Although tenants in a multitenancy architecture access the same application, they are securely isolated from each other. Furthermore, each tenant only has access to its own resources. Multitenancy is a common architectural approach for software-as-a-service (SaaS) and cloud computing applications. In general, clients (or tenants) accessing a SaaS are accessing the same application, but each one is isolated from the others and has its own resources.&lt;/p&gt; &lt;p&gt;A multitenant architecture must isolate the data available to each tenant. If there is a problem with one tenant&amp;#8217;s data set, it won&amp;#8217;t impact the other tenants. In a relational database, we use a database or a schema to isolate each tenant&amp;#8217;s data. One way to separate data is to give each tenant access to its own database or schema. Another option, which is available if you are using a relational database with JPA and Hibernate, is to partition a single database for multiple tenants. In this article, I focus on the standalone database and schema options. I won&amp;#8217;t demonstrate how to set up a partition.&lt;/p&gt; &lt;p&gt;In a server-based application like WildFly, multitenancy is different from the conventional approach. In this case, the server application works directly with the data source by initiating a connection and preparing the database to be used. The client application does not spend time opening the connection, which improves performance. On the other hand, using Enterprise JavaBeans (EJBs) for container-managed transactions can lead to problems. As an example, the server-based application could do something to generate an error to commit or roll the application back.&lt;/p&gt; &lt;h2&gt;Implementation code&lt;/h2&gt; &lt;p&gt;Two interfaces are crucial to implementing multitenancy in JPA and Hibernate:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;MultiTenantConnectionProvider&lt;/strong&gt; is responsible for connecting tenants to their respective databases and services. We will use this interface and a tenant identifier to switch between databases for different tenants.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;CurrentTenantIdentifierResolver&lt;/strong&gt; is responsible for identifying the tenant. We will use this interface to define what is considered a tenant (more about this later). We will also use this interface to provide the correct tenant identifier to &lt;code&gt;MultiTenantConnectionProvider&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In JPA, we configure these interfaces using the &lt;code&gt;persistence.xml&lt;/code&gt; file. In the next sections, I&amp;#8217;ll show you how to use these two interfaces to create the first three classes we need for our multitenancy architecture: &lt;code&gt;DatabaseMultiTenantProvider&lt;/code&gt;, &lt;code&gt;MultiTenantResolver&lt;/code&gt;, and &lt;code&gt;DatabaseTenantResolver&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;DatabaseMultiTenantProvider&lt;/h3&gt; &lt;p&gt;&lt;code&gt;DatabaseMultiTenantProvider&lt;/code&gt; is an implementation of the &lt;code&gt;MultiTenantConnectionProvider&lt;/code&gt; interface. This class contains logic to switch to the database that matches the given tenant identifier. In WildFly, this means switching to different &lt;em&gt;data sources&lt;/em&gt;. The &lt;code&gt;DatabaseMultiTenantProvider&lt;/code&gt; class also implements the &lt;code&gt;ServiceRegistryAwareService&lt;/code&gt;, which allows us to inject a service during the configuration phase.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s the code for the &lt;code&gt;DatabaseMultiTenantProvider&lt;/code&gt; class:&lt;/p&gt; &lt;pre&gt;public class DatabaseMultiTenantProvider implements MultiTenantConnectionProvider, ServiceRegistryAwareService{ private static final long serialVersionUID = 1L; private static final String TENANT_SUPPORTED = "DATABASE"; private DataSource dataSource; private String typeTenancy ; @Override public boolean supportsAggressiveRelease() { return false; } @Override public void injectServices(ServiceRegistryImplementor serviceRegistry) { typeTenancy = (String) ((ConfigurationService)serviceRegistry .getService(ConfigurationService.class)) .getSettings().get("hibernate.multiTenancy"); dataSource = (DataSource) ((ConfigurationService)serviceRegistry .getService(ConfigurationService.class)) .getSettings().get("hibernate.connection.datasource"); } @SuppressWarnings("rawtypes") @Override public boolean isUnwrappableAs(Class clazz) { return false; } @Override public &amp;#60;T&amp;#62; T unwrap(Class&amp;#60;T&amp;#62; clazz) { return null; } @Override public Connection getAnyConnection() throws SQLException { final Connection connection = dataSource.getConnection(); return connection; } @Override public Connection getConnection(String tenantIdentifier) throws SQLException { final Context init; //Just use the multi-tenancy if the hibernate.multiTenancy == DATABASE &lt;strong&gt;if(TENANT_SUPPORTED.equals(typeTenancy)) {&lt;/strong&gt; try { init = new InitialContext(); &lt;strong&gt; dataSource = (DataSource) init.lookup("java:/jdbc/" + tenantIdentifier);&lt;/strong&gt; } catch (NamingException e) { throw new HibernateException("Error trying to get datasource ['java:/jdbc/" + tenantIdentifier + "']", e); } } return dataSource.getConnection(); } @Override public void releaseAnyConnection(Connection connection) throws SQLException { connection.close(); } @Override public void releaseConnection(String tenantIdentifier, Connection connection) throws SQLException { releaseAnyConnection(connection); } } &lt;/pre&gt; &lt;p&gt;As you can see, we call the &lt;code&gt;injectServices&lt;/code&gt; method to populate the &lt;code&gt;datasource&lt;/code&gt; and &lt;code&gt;typeTenancy&lt;/code&gt; attributes. We use the &lt;code&gt;datasource&lt;/code&gt; attribute to get a connection from the data source, and we use the &lt;code&gt;typeTenancy&lt;/code&gt; attribute to find out if the class supports the &lt;code&gt;multiTenancy&lt;/code&gt; type. We call the &lt;code&gt;getConnection&lt;/code&gt; method to get a data source connection. This method uses the tenant identifier to locate and switch to the correct data source.&lt;/p&gt; &lt;h3&gt;MultiTenantResolver&lt;/h3&gt; &lt;p&gt;&lt;code&gt;MultiTenantResolver&lt;/code&gt; is an abstract class that implements the &lt;code&gt;CurrentTenantIdentifierResolver&lt;/code&gt; interface. This class aims to provide a &lt;code&gt;setTenantIdentifier&lt;/code&gt; method to all &lt;code&gt;CurrentTenantIdentifierResolver&lt;/code&gt; implementations:&lt;/p&gt; &lt;pre&gt;public abstract class MultiTenantResolver implements CurrentTenantIdentifierResolver { &lt;strong&gt;protected String tenantIdentifier; public void setTenantIdentifier(String tenantIdentifier) { this.tenantIdentifier = tenantIdentifier; } &lt;/strong&gt;} &lt;/pre&gt; &lt;p&gt;This abstract class is simple. We only use it to provide the &lt;code&gt;setTenantIdentifier&lt;/code&gt; method.&lt;/p&gt; &lt;h3&gt;DatabaseTenantResolver&lt;/h3&gt; &lt;p&gt;&lt;code&gt;DatabaseTenantResolver&lt;/code&gt; also implements the &lt;code&gt;CurrentTenantIdentifierResolver&lt;/code&gt; interface. This class is the concrete class of &lt;code&gt;MultiTenantResolver&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;public class DatabaseTenantResolver extends MuiltiTenantResolver { private Map&amp;#60;String, String&amp;#62; regionDatasourceMap; public DatabaseTenantResolver(){ &lt;strong&gt;regionDatasourceMap = new HashMap();&lt;/strong&gt; &lt;strong&gt; regionDatasourceMap.put("default", "MyDataSource");&lt;/strong&gt; &lt;strong&gt; regionDatasourceMap.put("america", "AmericaDB");&lt;/strong&gt; &lt;strong&gt; regionDatasourceMap.put("europa", "EuropaDB");&lt;/strong&gt; &lt;strong&gt; regionDatasourceMap.put("asia", "AsiaDB");&lt;/strong&gt; } @Override public String resolveCurrentTenantIdentifier() { &lt;strong&gt;if(this.tenantIdentifier != null&lt;/strong&gt; &lt;strong&gt; &amp;#38;&amp;#38; regionDatasourceMap.containsKey(this.tenantIdentifier)){&lt;/strong&gt; &lt;strong&gt; return regionDatasourceMap.get(this.tenantIdentifier);&lt;/strong&gt; &lt;strong&gt; }&lt;/strong&gt; &lt;strong&gt; return regionDatasourceMap.get("default");&lt;/strong&gt; } @Override public boolean validateExistingCurrentSessions() { return false; } }&lt;/pre&gt; &lt;p&gt;Notice that &lt;code&gt;DatabaseTenantResolver&lt;/code&gt; uses a &lt;code&gt;Map&lt;/code&gt; to define the correct data source for a given tenant. The tenant, in this case, is a region. Note, too, that this example assumes we have the data sources &lt;code&gt;java:/jdbc/MyDataSource&lt;/code&gt;, &lt;code&gt;java:/jdbc/AmericaDB&lt;/code&gt;, &lt;code&gt;java:/jdbc/EuropaDB&lt;/code&gt;, and &lt;code&gt;java:/jdbc/AsiaDB&lt;/code&gt; configured in WildFly.&lt;/p&gt; &lt;h2&gt;Configure and define the tenant&lt;/h2&gt; &lt;p&gt;Now we need to use the &lt;code&gt;persistence.xml&lt;/code&gt; file to configure the tenant:&lt;/p&gt; &lt;pre&gt;&amp;#60;persistence&amp;#62; &amp;#60;persistence-unit name="jakartaee8"&amp;#62; &amp;#60;jta-data-source&amp;#62;jdbc/MyDataSource&amp;#60;/jta-data-source&amp;#62; &amp;#60;properties&amp;#62; &amp;#60;property name="javax.persistence.schema-generation.database.action" value="none" /&amp;#62; &amp;#60;property name="hibernate.dialect" value="org.hibernate.dialect.PostgresPlusDialect"/&amp;#62; &lt;strong&gt;&amp;#60;property name="hibernate.multiTenancy" value="DATABASE"/&amp;#62;&lt;/strong&gt; &lt;strong&gt;&amp;#60;property name="hibernate.tenant_identifier_resolver" value="net.rhuanrocha.dao.multitenancy.DatabaseTenantResolver"/&amp;#62;&lt;/strong&gt; &lt;strong&gt; &amp;#60;property name="hibernate.multi_tenant_connection_provider" value="net.rhuanrocha.dao.multitenancy.DatabaseMultiTenantProvider"/&amp;#62;&lt;/strong&gt; &amp;#60;/properties&amp;#62; &amp;#60;/persistence-unit&amp;#62; &amp;#60;/persistence&amp;#62; &lt;/pre&gt; &lt;p&gt;Next, we define the tenant in the &lt;code&gt;EntityManagerFactory&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;@PersistenceUnit protected EntityManagerFactory emf; protected EntityManager getEntityManager(String multitenancyIdentifier){ final MuiltiTenantResolver tenantResolver = (&lt;strong&gt;MuiltiTenantResolver&lt;/strong&gt;) ((SessionFactoryImplementor) emf).getCurrentTenantIdentifierResolver(); &lt;strong&gt; tenantResolver.setTenantIdentifier(multitenancyIdentifier);&lt;/strong&gt; return emf.createEntityManager(); } &lt;/pre&gt; &lt;p&gt;Note that we call the &lt;code&gt;setTenantIdentifier&lt;/code&gt; before creating a new instance of &lt;code&gt;EntityManager&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;I have presented a simple example of multitenancy in a database using JPA with Hibernate and WildFly. There are many ways to use a database for multitenancy. My main point has been to show you how to implement the &lt;code&gt;CurrentTenantIdentifierResolver&lt;/code&gt; and &lt;code&gt;MultiTenantConnectionProvider&lt;/code&gt; interfaces. I&amp;#8217;ve shown you how to use JPA&amp;#8217;s &lt;code&gt;persistence.xml&lt;/code&gt; file to configure the required classes based on these interfaces.&lt;/p&gt; &lt;p&gt;Keep in mind that for this example, I have assumed that WildFly manages the data source and connection pool and that EJB handles the container-managed transactions. In the second half of this series, I will provide a similar introduction to multitenancy, but using a schema rather than a database. If you want to go deeper with this example, you can &lt;a target="_blank" rel="nofollow" href="https://github.com/rhuan080/multitenancyJpaJakartaEE"&gt;find the complete application code and further instructions&lt;/a&gt; on my GitHub repository.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#38;linkname=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fjakarta-ee-multitenancy-with-jpa-on-wildfly-part-1%2F&amp;#038;title=Jakarta%20EE%3A%20Multitenancy%20with%20JPA%20on%20WildFly%2C%20Part%201" data-a2a-url="https://developers.redhat.com/blog/2020/06/15/jakarta-ee-multitenancy-with-jpa-on-wildfly-part-1/" data-a2a-title="Jakarta EE: Multitenancy with JPA on WildFly, Part 1"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/15/jakarta-ee-multitenancy-with-jpa-on-wildfly-part-1/"&gt;Jakarta EE: Multitenancy with JPA on WildFly, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7zZq2y1lyIQ" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this two-part series, I demonstrate two approaches to multitenancy with the Jakarta Persistence API (JPA) running on WildFly. In the first half of this series, you will learn how to implement multitenancy using a database. In the second half, I will introduce you to multitenancy using a schema. I based both examples on JPA [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/15/jakarta-ee-multitenancy-with-jpa-on-wildfly-part-1/"&gt;Jakarta EE: Multitenancy with JPA on WildFly, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">720037</post-id><dc:creator>rhsilva</dc:creator><dc:date>2020-06-15T07:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/15/jakarta-ee-multitenancy-with-jpa-on-wildfly-part-1/</feedburner:origLink></entry><entry><title>Tracking COVID-19 using Quarkus, AMQ Streams, and Camel K on OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QkUhNGsv0ds/" /><category term="Java" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Stream Processing" /><category term="Apache Kafka" /><category term="COVID-19" /><category term="kubernetes-native" /><category term="MongoDB" /><category term="openshift" /><author><name>gmccarth</name></author><id>https://developers.redhat.com/blog/?p=729337</id><updated>2020-06-15T07:00:04Z</updated><published>2020-06-15T07:00:04Z</published><content type="html">&lt;p&gt;In just a matter of weeks, the world that we knew changed forever. The COVID-19 pandemic came swiftly and caused massive disruption to our healthcare systems and local businesses, throwing the world&amp;#8217;s economies into chaos. The coronavirus quickly became a crisis that affected everyone. As researchers and scientists rushed to make sense of it, and find ways to eliminate or slow the rate of infection, countries started gathering statistics such as the number of confirmed cases, reported deaths, and so on. Johns Hopkins University researchers have since aggregated the &lt;a target="_blank" rel="nofollow" href="https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"&gt;statistics from many countries&lt;/a&gt; and made them available.&lt;/p&gt; &lt;p&gt;In this article, we demonstrate how to build a website that shows a series of COVID-19 graphs. These graphs reflect the accumulated number of cases and deaths over a given time period for each country. We use the &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Red Hat build of Quarkus, &lt;/a&gt;&lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/camel-k/latest/index.html#"&gt;Apache Camel K&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;Red Hat AMQ Streams&lt;/a&gt; to get the Johns Hopkins University data and populate a MongoDB database with it. The deployment is built on the &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift Container Platform (OCP)&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-729337"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The two applications developed for this demo would work for many other scenarios, such as reporting on corporate sales numbers, reporting on data from Internet-of-Things (IoT) connected devices, or keeping track of expenses or inventory. Wherever there is a repository with useful data, you could make minor code modifications and use these applications to collect, transform, and present the data to its users in a more meaningful way.&lt;/p&gt; &lt;h2&gt;Technologies we&amp;#8217;ll use&lt;/h2&gt; &lt;p&gt;Our focus in this article is the next-generation &lt;a href="https://developers.redhat.com/blog/2020/04/08/why-kubernetes-native-instead-of-cloud-native/"&gt;Kubernetes-native&lt;/a&gt; &lt;a target="_blank" rel="nofollow" href="http://developers.redhat.com/blog/2020/04/24/ramp-up-on-quarkus-a-kubernetes-native-java-framework/"&gt;Java framework&lt;/a&gt;, &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;. We also leverage existing frameworks such as Apache Camel K and Kafka (AMQ Streams) to reduce the amount of code that we need to write.&lt;/p&gt; &lt;h3&gt;What is Quarkus?&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.io/"&gt;Quarkus&lt;/a&gt; is a Kubernetes-native Java framework crafted from best-of-breed Java libraries and standards. We also sometimes refer to Quarkus as &lt;i&gt;supersonic, subatomic Java&lt;/i&gt;, and for a good reason: Quarkus offers fast boot times and low RSS memory (not just heap size) in container-orchestration platforms like &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;. Quarkus lets developers create Java applications that have a similar footprint to &lt;a href="https://developers.redhat.com/blog/category/node-js/"&gt;Node.js&lt;/a&gt;, or smaller.&lt;/p&gt; &lt;p&gt;For this demonstration, we chose to run our Quarkus apps on OCP. Running on OpenShift Container Platform means that our demo applications can run anywhere that OpenShift runs, which includes bare metal, Amazon Web Services (AWS), Azure, Google Cloud, IBM Cloud, vSphere, and more.&lt;/p&gt; &lt;h3&gt;What is Red Hat OpenShift?&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/products/container-platform"&gt;Red Hat OpenShift&lt;/a&gt; offers a consistent hybrid-cloud foundation for building and scaling containerized applications. OpenShift provides an enterprise-grade, container-based platform with no vendor lock-in. Red Hat was one of the first companies to work with Google on Kubernetes, even prior to launch, and has become the second leading contributor to the Kubernetes upstream project. Using OpenShift simplifies application deployment because we can easily create resources (such as the MongoDB database we&amp;#8217;re using for this demonstration) by entering just a couple of commands in the terminal. OpenShift also provides a common development platform no matter what infrastructure we use to host the application.&lt;/p&gt; &lt;h3&gt;What is Red Hat AMQ Streams?&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/products/red-hat-amq-streams"&gt;AMQ Streams&lt;/a&gt; is an enterprise-grade Apache Kafka (&lt;a href="https://developers.redhat.com/blog/category/stream-processing/"&gt;event streaming&lt;/a&gt;) solution, which enables systems to exchange data at high throughput and low latency. Using queues is a great way to ensure that our applications are loosely coupled. Kafka is an excellent product, providing a highly scalable, fault-tolerant message queue that is capable of handling large volumes of data with relative ease.&lt;/p&gt; &lt;h3&gt;What is Apache Camel K?&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/camel-k/latest/"&gt;Apache Camel K&lt;/a&gt; is a lightweight cloud-integration platform that runs natively on Kubernetes and supports automated cloud configurations. Based on the famous Apache Camel, Camel K is designed and optimized for serverless and microservices architectures. Camel offers hundreds of connectors, providing connectivity to many existing applications, frameworks, and platforms.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;For this demonstration, you will need the following technologies set up in your development environment:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;An OpenShift 4.3+ environment with Cluster Admin access&lt;/li&gt; &lt;li&gt;JDK 11 installed with &lt;code&gt;JAVA_HOME&lt;/code&gt; appropriately configured&lt;/li&gt; &lt;li&gt;Openshift CLI (&lt;code&gt;oc&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;Apache Maven 3.6.2+&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We will build two separate Quarkus applications and deploy them to our OpenShift environment. The first application retrieves all of the data from an online repository (the &lt;a target="_blank" rel="nofollow" href="https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"&gt;Johns Hopkins University GitHub repository&lt;/a&gt;) and uses that data to populate a MongoDB collection called &lt;code&gt;covid19report&lt;/code&gt;. The second application hosts the Quarkusian COVID-19 Tracker website, which dynamically generates charts based on the country that was selected. This application uses REST calls to query the MongoDB collection and returns the relevant data.&lt;/p&gt; &lt;h2&gt;Adding resources to the OpenShift environment&lt;/h2&gt; &lt;p&gt;Before we can get started with the two applications, we need to add the required resources to an OpenShift cluster. We&amp;#8217;ll add a MongoDB database first; then, we will add the Kafka cluster and create the Kafka topic to publish to.&lt;/p&gt; &lt;p&gt;Using &lt;code&gt;oc&lt;/code&gt;, log into your OpenShift environment, and create a new project called &lt;code&gt;covid-19-tracker&lt;/code&gt;. Then, add the MongoDB database to that namespace:&lt;/p&gt; &lt;pre&gt;$ oc new project covid-19-tracker $ oc new-app -n covid-19-tracker --docker-image mongo:4.0 --name=covid19report &lt;/pre&gt; &lt;p&gt;Next, log into the OpenShift console, go to the OperatorHub, and search for the AMQ Streams Operator. Figure 1 shows all of the AMQ installations available from the OperatorHub.&lt;/p&gt; &lt;div id="attachment_730147" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/OperatorHub-AMQ.png"&gt;&lt;img aria-describedby="caption-attachment-730147" class="wp-image-730147 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/OperatorHub-AMQ-1024x518.png" alt="A screenshot of the AMQ Streams page in the OperatorHub." width="640" height="324" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/OperatorHub-AMQ-1024x518.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/OperatorHub-AMQ-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/OperatorHub-AMQ-768x389.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/OperatorHub-AMQ.png 1579w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730147" class="wp-caption-text"&gt;Figure 1. Search for the AMQ Streams Operator in the OpenShift OperatorHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Install the &lt;b&gt;Red Hat Integration &amp;#8211; AMQ Streams&lt;/b&gt; Operator. After the Operator is successfully installed, go to &lt;b&gt;Installed Operators&lt;/b&gt;, and click on it. You should see a screen similar to Figure 2.&lt;/p&gt; &lt;div id="attachment_730167" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/RedHatIntegration-AMQStreams.png"&gt;&lt;img aria-describedby="caption-attachment-730167" class="wp-image-730167 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/RedHatIntegration-AMQStreams-1024x512.png" alt="A screenshot of all of the available APIs for the Red Hat Integration - AMQ Streams Operator." width="640" height="320" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/RedHatIntegration-AMQStreams-1024x512.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/RedHatIntegration-AMQStreams-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/RedHatIntegration-AMQStreams-768x384.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730167" class="wp-caption-text"&gt;Figure 2. A listing of available APIs for the Red Hat Integration &amp;#8211; AMQ Streams Operator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Select the Kafka tile and click &lt;b&gt;Create Instance&lt;/b&gt;. Create the Kafka instance with default settings. Creating this instance launches seven pods: One pod is for the Kafka Cluster Entity Operator, and there are three pods each for the Kafka cluster and Zookeeper cluster.&lt;/p&gt; &lt;p&gt;Once all seven pods are running, go back to the &lt;b&gt;Installed Operators &lt;/b&gt;page, and again select the &lt;strong&gt;Red Hat Integration &amp;#8211; AMQ Streams Operator&lt;/strong&gt;. This time, select the &lt;strong&gt;Kafka Topic&lt;/strong&gt; tile and click &lt;b&gt;Create Instance&lt;/b&gt;. You will see the option to create and configure the Kafka topic for our demonstration, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_730177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/CreateKafkaTopic.png"&gt;&lt;img aria-describedby="caption-attachment-730177" class="wp-image-730177" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/CreateKafkaTopic.png" alt="A screenshot of the YAML file to create the Kafka topic." width="640" height="441" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/CreateKafkaTopic.png 720w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/CreateKafkaTopic-300x207.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730177" class="wp-caption-text"&gt;Figure 3. Create a Kafka topic by manually entering the required YAML or JSON definitions.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In this case, we need to make just one change to the YAML file. Change the topic&amp;#8217;s name (&lt;code&gt;metadata: name&lt;/code&gt;) to: &lt;code&gt;jhucsse&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Leave everything else in the file as the default values, then create the topic. Now the Kafka environment is ready to accept the data from our Quarkus applications.&lt;/p&gt; &lt;p&gt;For our Quarkus apps to connect to Kafka and MongoDB, we need to make a note of the cluster IP addresses for those services. Run the following from the command line, and you will be presented with a list of services and their corresponding internal IPs:&lt;/p&gt; &lt;pre&gt;$ oc get services &lt;/pre&gt; &lt;p&gt;Figure 4 shows the list of available services and each one&amp;#8217;s internal IP address:&lt;/p&gt; &lt;div id="attachment_730267" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc_get_services-3.png"&gt;&lt;img aria-describedby="caption-attachment-730267" class="wp-image-730267" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc_get_services-3.png" alt="A screenshot of available services and their associated IP addresses in the terminal." width="640" height="61" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc_get_services-3.png 975w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc_get_services-3-300x29.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc_get_services-3-768x73.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730267" class="wp-caption-text"&gt;Figure 4. Available services in the cluster.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Make a note of the IP address for &lt;code&gt;my-cluster-kafka-bootstrap&lt;/code&gt; and &lt;code&gt;covid19report&lt;/code&gt;. Later, we&amp;#8217;ll add these values to the &lt;code&gt;application.properties&lt;/code&gt; file for each of our Quarkus applications.&lt;/p&gt; &lt;h2&gt;Preparing the Quarkus applications&lt;/h2&gt; &lt;p&gt;Before going any further, you should either download and unzip or clone the two demo applications to your local machine. The source code is available at the following URLs:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Application 1 (&lt;code&gt;covid-data-fetching)&lt;/code&gt;&lt;/strong&gt;: &lt;a target="_blank" rel="nofollow" href="https://github.com/gmccarth/covid-data-fetching"&gt;https://github.com/gmccarth/covid-data-fetching&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Application 2 (&lt;code&gt;covid-19-tracker)&lt;/code&gt;&lt;/strong&gt;: &lt;a target="_blank" rel="nofollow" href="https://github.com/gmccarth/covid-19-tracker"&gt;https://github.com/gmccarth/covid-19-tracker&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;After you extract the code, you will need to modify the &lt;code&gt;application.properties&lt;/code&gt; file for each application to ensure that the Quarkus apps can connect to the MongoDB database and Kafka cluster we set up earlier.&lt;/p&gt; &lt;h3&gt;Modify the application.properties for Application 1&lt;/h3&gt; &lt;p&gt;In the &lt;code&gt;application.properties&lt;/code&gt; for Application 1 (&lt;code&gt;covid-data-fetching&lt;/code&gt;), find the two lines that start with &lt;code&gt;quarkus.mongodb&lt;/code&gt;. Replace the IP addresses after &lt;code&gt;mongodb://&lt;/code&gt; with the IP address for our MongoDB pod (&lt;code&gt;covid19report&lt;/code&gt;), which you noted earlier. Be sure to include the correct port, which is 27017:&lt;/p&gt; &lt;pre&gt;quarkus.mongodb.connection-string=mongodb://&lt;em&gt;&amp;#60;the IP for covid19report&amp;#62;&lt;/em&gt;:27017 quarkus.mongodb.hosts=mongodb://&lt;em&gt;&amp;#60;the IP for covid19report&amp;#62;&lt;/em&gt;:27017 &lt;em&gt;For example:&lt;/em&gt; quarkus.mongodb.connection-string=mongodb://172.30.195.119:27017 quarkus.mongodb.hosts=mongodb://172.30.195.119:27017&lt;/pre&gt; &lt;p&gt;Similarly, find the &lt;code&gt;camel.component.kafka.brokers&lt;/code&gt; line and replace the IP address with the &lt;code&gt;my-cluster-kafka-bootstrap&lt;/code&gt; IP address. Use port 9092 for this service:&lt;/p&gt; &lt;pre&gt;camel.component.kafka.brokers=&lt;em&gt;&amp;#60;the IP for my-cluster-kafka-bootstrap&amp;#62;&lt;/em&gt;:9092 &lt;/pre&gt; &lt;h3&gt;Modify the application.properties for Application 2&lt;/h3&gt; &lt;p&gt;Now open Application 2 (&lt;code&gt;covid-19-tracker&lt;/code&gt;) and find the &lt;code&gt;quarkus.mongodb.connection-string&lt;/code&gt;. Replace the IP address with the IP address for our MongoDB pod:&lt;/p&gt; &lt;pre&gt;quarkus.mongodb.connection-string=mongodb://&lt;em&gt;&amp;#60;the IP for covid19report&amp;#62;&lt;/em&gt;:27017 &lt;/pre&gt; &lt;p&gt;Similarly, find the &lt;code&gt;camel.component.kafka.brokers&lt;/code&gt; line and replace the IP address with the &lt;code&gt;my-cluster-kafka-bootstrap&lt;/code&gt;IP address. Use port 9092 for this service.&lt;/p&gt; &lt;h2&gt;Set up and run the first application&lt;/h2&gt; &lt;p&gt;For our first application, we use Apache Camel to retrieve files directly from the Johns Hopkins University GitHub repository URL. Camel transforms the CSV files into individual records, which we place into a Kafka topic. A second Camel route then consumes the messages from the Kafka topic. It transforms each record into a database object and inserts that data into a MongoDB collection. We&amp;#8217;ll go through each of these phases in detail.&lt;/p&gt; &lt;h3&gt;Phase 1: Retrieve the data from the repository, transform it, and publish it to a Kafka topic&lt;/h3&gt; &lt;p&gt;Figure 5 shows a flow diagram of the CSV files being retrieved from the GitHub repository and placed in a Kafka topic.&lt;/p&gt; &lt;div id="attachment_730317" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase1.png"&gt;&lt;img aria-describedby="caption-attachment-730317" class="wp-image-730317 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase1-1024x981.png" alt="A flow diagram of the CSV files being retrieved from the shared repository and placed in the Kafka topic." width="640" height="613" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase1-1024x981.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase1-300x287.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase1-768x735.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase1.png 1130w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730317" class="wp-caption-text"&gt;Figure 5. Retrieve the data from the repository, transform it, and publish it to a Kafka topic.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You can find the code for this phase in the &lt;code&gt;JhuCsseExtractor.java&lt;/code&gt; file:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;First, we use a Camel route to get the CSV files from the Johns Hopkins University source: &lt;pre&gt;from("timer:jhucsse?repeatCount=1") .setHeader("nextFile", simple("02-01-2020")) .setHeader("version", simple("v1")) .loopDoWhile(method(this, "dateInValidRange(${header.nextFile})")) .setHeader("nextFile", method(this,      "computeNextFile(${header.nextFile})")) .setHeader("version", method(this, "getVersion(${header.nextFile})")) .toD("https:{{jhu.csse.baseUrl}}/${header.nextFile}.csv?httpMethod=GET") .log(LoggingLevel.DEBUG,"after setHeader:nextFile=${header.nextFile}") .split().tokenize("\n", 1, true) .log(LoggingLevel.DEBUG,"version=${header.version}") .choice() .when(header("version").isEqualTo("v1")) .unmarshal().bindy(BindyType.Csv, JhuCsseDailyReportCsvRecordv1.class) .marshal().json(JsonLibrary.Jackson) .to("kafka:jhucsse") .otherwise() .unmarshal().bindy(BindyType.Csv, JhuCsseDailyReportCsvRecordv2.class) .marshal().json(JsonLibrary.Jackson) .to("kafka:jhucsse") .end(); &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Next, we use a &lt;code&gt;loopDoWhile&lt;/code&gt; to fetch all of the CSV files for the specified date range.&lt;/li&gt; &lt;li&gt;At this point, the CSV format changes to include additional data from &lt;code&gt;03-22-2020.csv&lt;/code&gt; onward. We use a &lt;code&gt;choice&lt;/code&gt; method to handle the change in data format. The &lt;code&gt;choice&lt;/code&gt; method ensures that all of the data is correctly inserted into the Kafka topic.&lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;Phase 2: Consume the messages in the Kafka topic and write them to the MongoDB collection&lt;/h3&gt; &lt;p&gt;Figure 6 shows a flow diagram of the transformed records being placed in the MongoDB collection.&lt;/p&gt; &lt;div id="attachment_730337" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase2.png"&gt;&lt;img aria-describedby="caption-attachment-730337" class="wp-image-730337 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase2-1024x915.png" alt="A flow diagram of the database objects being sent to the MongoDB database." width="640" height="572" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase2-1024x915.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase2-300x268.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase2-768x686.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Phase2.png 1110w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730337" class="wp-caption-text"&gt;Figure 6. Consume the messages in the Kafka topic and write them to the MongoDB collection.&lt;/p&gt;&lt;/div&gt; &lt;ol&gt; &lt;li&gt;In a different bean (&lt;code&gt;MongoDbPopulator.java&lt;/code&gt;), we configure another Camel route to consume the messages from the Kafka topic we developed in Phase 1. The Camel route will write those messages to our MongoDB database: &lt;pre&gt;fromF("kafka:jhucsse?brokers=%s",brokers)         .log("message: ${body}")         .toF("mongodb:mongoClient?database=%s&amp;#38;collection=%s&amp;#38;operation=insert", database, collection); &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;To run the Quarkus app, in our terminal, we need to be in the &lt;code&gt;../covid-data-fetching/&lt;/code&gt; directory. Type the following into the terminal to kick-off building and deploying the Quarkus application: &lt;pre&gt;./mvnw clean package -Dquarkus.kubernetes.deploy=true -DskipTests=true -Dquarkus.kubernetes-client.trust-certs=true -Dquarkus.s2i.base-jvm-image=fabric8/s2i-java:latest-java11 &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;When you see the &lt;code&gt;BUILD SUCCESS&lt;/code&gt; message, go to your OpenShift console, where the &lt;code&gt;covid-data-fetching&lt;/code&gt; application should be starting to run. To view the Camel route in action, go to the &lt;code&gt;covid19report&lt;/code&gt; pod&amp;#8217;s &lt;strong&gt;Logs&lt;/strong&gt; tab, where you should see something similar to Figure 7, a screenshot of messages flowing into Kafka. &lt;p&gt;&lt;div id="attachment_730187" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/KafkaStreamingLogs.png"&gt;&lt;img aria-describedby="caption-attachment-730187" class="wp-image-730187 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/KafkaStreamingLogs-1024x486.png" alt="A screenshot of messages streaming into Kafka." width="640" height="304" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/KafkaStreamingLogs-1024x486.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/KafkaStreamingLogs-300x142.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/KafkaStreamingLogs-768x364.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/KafkaStreamingLogs.png 1586w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730187" class="wp-caption-text"&gt;Figure 7. The application logs show a message stream flowing into Kafka.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;To confirm that the records are being written to MongoDB, go to the &lt;b&gt;Terminal&lt;/b&gt; tab of the &lt;code&gt;covid19report&lt;/code&gt; pod and type &lt;code&gt;Mongo&lt;/code&gt; in the terminal window. This command launches the MongoDB shell. In the shell type &lt;code&gt;show dbs&lt;/code&gt; to see a list of databases, which should include &lt;code&gt;covid19report&lt;/code&gt;. Figure 8 shows the list of databases. &lt;p&gt;&lt;div id="attachment_730367" style="width: 248px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/MongoShowDbs.png"&gt;&lt;img aria-describedby="caption-attachment-730367" class="wp-image-730367 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/MongoShowDbs.png" alt="A screenshot showing a list of databases, including covid19report." width="238" height="126" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730367" class="wp-caption-text"&gt;Figure 8. The list of databases should include covid19report.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Set up and run the second application&lt;/h2&gt; &lt;p&gt;Application 2 is the Quarkusian COVID-19 Tracker web application. It uses REST calls to the MongoDB database to dynamically retrieve a requested data set, then launches the website. Figure 9 shows a flow diagram for the COVID-19 Tracker.&lt;/p&gt; &lt;div id="attachment_730377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture.png"&gt;&lt;img aria-describedby="caption-attachment-730377" class="wp-image-730377 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture-1024x1015.png" alt="A flow diagram of a COVID-19 data set being retrieved from MongoDB." width="640" height="634" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture-1024x1015.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture-300x297.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture-768x761.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Application2Architecture.png 1378w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730377" class="wp-caption-text"&gt;Figure 9. A COVID-19 data set is dynamically retrieved from the MongoDB database.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Notes about this application:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;When we run Quarkus, a web server is started and is accessible on port 8080.&lt;/li&gt; &lt;li&gt;Our Quarkus project included RESTEasy JAX-RS. This allows us to create multiple REST endpoints for the MongoDB queries.&lt;/li&gt; &lt;li&gt;Quarkus also supports dependency injection, so we can easily inject a companion bean into our main class.&lt;/li&gt; &lt;li&gt;Our &lt;code&gt;index.html&lt;/code&gt; page (in the &lt;code&gt;resources/META-INF&lt;/code&gt; folder) has a dropdown list to select the specific, country-based data set that we want to use. The dropdown list is populated from a query to the MongoDB database. On submit, the page sends the country code in a &lt;code&gt;GET&lt;/code&gt; request to the &lt;code&gt;TrackerResource&lt;/code&gt; bean. The bean uses &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/mongodb-panache"&gt;Panache&lt;/a&gt; to query the MongoDB database. It then returns the response to the web page, which generates a graph from the received JSON response.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To run the Quarkus app, we need to be in the &lt;code&gt;../covid-19-tracker/&lt;/code&gt; directory. Type the following into the terminal to kick-off building and deploying this Quarkus application:&lt;/p&gt; &lt;pre&gt;$ ./mvnw clean package -Dquarkus.kubernetes.deploy=true -DskipTests=true -Dquarkus.kubernetes-client.trust-certs=true -Dquarkus.s2i.base-jvm-image=fabric8/s2i-java:latest-java11 &lt;/pre&gt; &lt;p&gt;After you see the &lt;code&gt;BUILD SUCCESS&lt;/code&gt; message, go to your OpenShift console and confirm that the &lt;code&gt;covid-19-tracker&lt;/code&gt; application is starting to run. Once the pod is running, you need to expose the service, so that you can get a route to it from the internet. In the terminal, type:&lt;/p&gt; &lt;pre&gt;$ oc expose svc/covid-19-tracker&lt;/pre&gt; &lt;p&gt;In your OpenShift console, in the administrator&amp;#8217;s perspective, go to &lt;b&gt;Networking&lt;/b&gt; -&amp;#62; &lt;b&gt;Routes&lt;/b&gt; to get the application URL. Click on the URL, which takes you to the application. Try selecting data sets from different countries. You should see something like the screenshot in Figure 10, with the charts changing to show the COVID-19 data for the country that you have selected.&lt;/p&gt; &lt;div id="attachment_730387" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Website.png"&gt;&lt;img aria-describedby="caption-attachment-730387" class="wp-image-730387 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Website-1024x555.png" alt="A screenshot of the web page showing confirmed cases for the United Kingdom." width="640" height="347" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Website-1024x555.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Website-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Website-768x417.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Website.png 1366w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730387" class="wp-caption-text"&gt;Figure 10. The COVID-19 Tracker shows data results from whatever country is selected.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to extract meaningful visualizations from an external repository with relative ease, and with very few lines of code. We used existing, solid frameworks to reduce complexity and the time required to build a reusable application. Deploying the application to OpenShift reduced the time necessary to develop, build, and deploy the demo applications. Additionally, Quarkus requires substantially less memory than a standard Java application. As a result, we built applications with faster launch times and quicker responses, resulting in an improved experience for developers, end-users, and ultimately, the business.&lt;/p&gt; &lt;p&gt;Are you interested in trying out Quarkus? Check out our self-paced &lt;a href="https://developers.redhat.com/courses/quarkus/getting-started/"&gt;Getting Started with Quarkus&lt;/a&gt; lab!  See the &lt;a href="https://developers.redhat.com/summit/2020/self-paced/"&gt;entire catalog&lt;/a&gt; for more developer labs.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: I would like to thank Mary Cochran, Claus Ibsen, and Josh Reagan, who assisted with troubleshooting and pointed me in the right direction for this article. Special thanks, also, to my fellow Hackfest team members: Jochen Cordes and Bruno Machado, who helped with building the Camel routes and configuring the MongoDB database.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#38;linkname=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Ftracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift%2F&amp;#038;title=Tracking%20COVID-19%20using%20Quarkus%2C%20AMQ%20Streams%2C%20and%20Camel%20K%20on%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/06/15/tracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift/" data-a2a-title="Tracking COVID-19 using Quarkus, AMQ Streams, and Camel K on OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/15/tracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift/"&gt;Tracking COVID-19 using Quarkus, AMQ Streams, and Camel K on OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QkUhNGsv0ds" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In just a matter of weeks, the world that we knew changed forever. The COVID-19 pandemic came swiftly and caused massive disruption to our healthcare systems and local businesses, throwing the world&amp;#8217;s economies into chaos. The coronavirus quickly became a crisis that affected everyone. As researchers and scientists rushed to make sense of it, and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/15/tracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift/"&gt;Tracking COVID-19 using Quarkus, AMQ Streams, and Camel K on OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">729337</post-id><dc:creator>gmccarth</dc:creator><dc:date>2020-06-15T07:00:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/15/tracking-covid-19-using-quarkus-amq-streams-and-camel-k-on-openshift/</feedburner:origLink></entry><entry><title>Supersonic, Subatomic Java Hackathon: June 15 – July 22 2020</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/V95W1arB1GY/" /><category term="Java" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Serverless" /><category term="cloud native java" /><category term="hackathon" /><category term="kubernetes-native" /><author><name>jebeck</name></author><id>https://developers.redhat.com/blog/?p=732287</id><updated>2020-06-15T07:00:00Z</updated><published>2020-06-15T07:00:00Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;The &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="http://quarkus.io/"&gt;&lt;span style="font-weight: 400;"&gt;Quarkus&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; community is excited to announce the &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://quarkus.devpost.com/"&gt;&lt;span style="font-weight: 400;"&gt;Supersonic, Subatomic Java Hackathon&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; for developers &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;to create Kubernetes-native applications for a chance to win &lt;/span&gt;&lt;b&gt;$30,000&lt;/b&gt;&lt;span style="font-weight: 400;"&gt; in prizes. This hackathon is a great opportunity to learn about the future of &lt;a href="https://developers.redhat.com/blog/2020/04/08/why-kubernetes-native-instead-of-cloud-native/"&gt;cloud-native&lt;/a&gt; Java development and showcase your coding skills.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;If you are new to Quarkus, don’t worry.  The community will be there to help and support you with a number of enablement sessions (see below) throughout the hackathon including an opening ceremony, weekly office hours, and the &lt;/span&gt;&lt;a href="https://developers.redhat.com/devnation/master-course/quarkus/?sc_cid=7013a000002gWC9AAM"&gt;&lt;span style="font-weight: 400;"&gt;DevNation Quarkus Master Course&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; series.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The hackathon will run from Monday, June 15th through Wednesday, July 22nd culminating in a &amp;#8220;live&amp;#8221; judging and award ceremony on Friday, August 14th.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;To register, &lt;a target="_blank" rel="nofollow" href="https://quarkus.devpost.com/"&gt;click here&lt;/a&gt;!&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;&lt;span id="more-732287"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Prize categories&lt;/h2&gt; &lt;p&gt;Five categories of prizes are available:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Best Overall: $10,000&lt;/li&gt; &lt;li&gt;Best Serverless App: $5,000&lt;/li&gt; &lt;li&gt;Best Kubernetes-native App: $5,000&lt;/li&gt; &lt;li&gt;Best IoT App: $5,000&lt;/li&gt; &lt;li&gt;Best Migrated App: $5,000&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Judges&lt;/h2&gt; &lt;p&gt;Our panel of judges:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://twitter.com/AdamBien?s=20"&gt;&lt;span style="font-weight: 400;"&gt;Adam Bien&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; (Java Champion, author, consultant)&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://twitter.com/jtgreene?s=20"&gt;&lt;span style="font-weight: 400;"&gt;Jason Greene&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; (Red hat Distinguished Engineer, Quarkus Community Leader) &lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://twitter.com/karesti?s=20"&gt;&lt;span style="font-weight: 400;"&gt;Katia Aresti&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; (Java Champion, Red Hat Senior Software Engineer)&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://www.linkedin.com/in/ken-johnson-kzj/"&gt;&lt;span style="font-weight: 400;"&gt;Ken Johnson&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; (Vice President, Red Hat Application Services)&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;&lt;b&gt;Enablement sessions&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Attend our enablement sessions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Wed, Jun 17th @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Opening Ceremony&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Mon, Jun 22nd) DevNation Quarkus &lt;/span&gt;&lt;a href="https://developers.redhat.com/devnation/master-course/quarkus/?sc_cid=7013a000002gWC9AAM"&gt;&lt;span style="font-weight: 400;"&gt;Master Course I&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; &amp;#8211; Quarkus Basics&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Wed, Jun 24th) DevNation Quarkus &lt;/span&gt;&lt;a href="https://developers.redhat.com/devnation/master-course/quarkus/?sc_cid=7013a000002gWC9AAM"&gt;&lt;span style="font-weight: 400;"&gt;Master Course II&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; &amp;#8211; Quarkus Cloud-Native&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Thurs, Jun 25th @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Quarkus Office Hours&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Wed, Jul 1st @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Quarkus Office Hours&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Wed, Jul 8th @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Quarkus Office Hours&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Wed, Jul 15th @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Quarkus Office Hours&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Wed, Jul 22nd @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Closing Ceremony&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;(Fri, Aug 14th @ 10 AM EST) &lt;/span&gt;&lt;a target="_blank" rel="nofollow" href="https://youtube.com/quarkusio/live"&gt;&lt;span style="font-weight: 400;"&gt;Live Judging and Winner Announcement&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#38;linkname=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F15%2Fsupersonic-subatomic-java-hackathon-june-15-july-22-2020%2F&amp;#038;title=Supersonic%2C%20Subatomic%20Java%20Hackathon%3A%20June%2015%20%E2%80%93%20July%2022%202020" data-a2a-url="https://developers.redhat.com/blog/2020/06/15/supersonic-subatomic-java-hackathon-june-15-july-22-2020/" data-a2a-title="Supersonic, Subatomic Java Hackathon: June 15 – July 22 2020"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/15/supersonic-subatomic-java-hackathon-june-15-july-22-2020/"&gt;Supersonic, Subatomic Java Hackathon: June 15 &amp;#8211; July 22 2020&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/V95W1arB1GY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Quarkus community is excited to announce the Supersonic, Subatomic Java Hackathon for developers to create Kubernetes-native applications for a chance to win $30,000 in prizes. This hackathon is a great opportunity to learn about the future of cloud-native Java development and showcase your coding skills. If you are new to Quarkus, don’t worry.  The [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/15/supersonic-subatomic-java-hackathon-june-15-july-22-2020/"&gt;Supersonic, Subatomic Java Hackathon: June 15 &amp;#8211; July 22 2020&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">732287</post-id><dc:creator>jebeck</dc:creator><dc:date>2020-06-15T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/15/supersonic-subatomic-java-hackathon-june-15-july-22-2020/</feedburner:origLink></entry><entry><title>Event streaming and data federation: A citizen integrator’s story</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3vF8QZhP7kA/" /><category term="Event-Driven" /><category term="Java" /><category term="Kubernetes" /><category term="Stream Processing" /><category term="data federation" /><category term="Data Virtualization" /><category term="Kafka connector" /><category term="openshift" /><author><name>snandaku</name></author><id>https://developers.redhat.com/blog/?p=721337</id><updated>2020-06-12T07:00:33Z</updated><published>2020-06-12T07:00:33Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;Businesses are seeking to benefit from every customer interaction with real-time personalized experience&lt;/span&gt;. Targeting each customer with relevant offers can greatly improve customer loyalty, but we must first understand the customer. We have to be able to draw on data and other resources from diverse systems, such as marketing, customer service, fraud, and business operations. With the advent of modern technologies and agile methodologies, we also want to be able to &lt;a target="_blank" rel="nofollow" href="https://www.computerweekly.com/microscope/opinion/In-pursuit-of-agility-empowering-the-citizen-integrator"&gt;empower citizen integrators&lt;/a&gt; (typically business users who understand business and client needs) to create custom software. What we need is &lt;span style="font-weight: 400;"&gt;one single functional domain where the information is harmonized in a homogeneous way. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;In this article, I will show you how to use &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/integration"&gt;Red Hat Integration&lt;/a&gt; to create a personalized customer experience. Figure 1 shows a high-level overview of the integration architecture we&amp;#8217;ll use for the example.&lt;/p&gt; &lt;div id="attachment_731697" style="width: 530px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-731697" class="wp-image-731697" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/high_level_arch-300x179.jpg" alt="" width="520" height="310" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/high_level_arch-300x179.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/high_level_arch.jpg 739w" sizes="(max-width: 520px) 100vw, 520px" /&gt;&lt;p id="caption-attachment-731697" class="wp-caption-text"&gt;Figure 1: Loyalty Management Application&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Let&amp;#8217;s start by looking at the use case for a Loyalty Management application; then, I&amp;#8217;ll introduce the technologies we&amp;#8217;ll use for the integration.&lt;/p&gt; &lt;h2&gt;Loyalty Management Use Case&lt;/h2&gt; &lt;p&gt;Our example application fulfills a use case of sending offers to customers in realtime. When a customer performs a transaction, it enters the event stream. For every event, we fetch the customer context and perform two simple checks:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Is the customer a &lt;code&gt;PLATINUM&lt;/code&gt; or &lt;code&gt;GOLD&lt;/code&gt; user?&lt;/li&gt; &lt;li&gt;Is the customer&amp;#8217;s predictive loyalty segmentation &lt;code&gt;HIGH&lt;/code&gt; or &lt;code&gt;MEDIUM&lt;/code&gt;?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We&amp;#8217;ll then use this information to determine whether to extend an offer to the given customer.&lt;/p&gt; &lt;h2&gt;Architectural overview&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/integration"&gt;Red Hat Integration&lt;/a&gt; is a set of integration and messaging products that provide API connectivity, data transformation, service composition, and more. For the example application, we&amp;#8217;ll use Red Hata Data Virtualization, Red Hat Fuse Online, and Red Hat AMQ Streams. Figure 2 shows the architecture and technologies used by our architecture.&lt;/p&gt; &lt;div id="attachment_731717" style="width: 558px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-731717" class="wp-image-731717" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/tech_stack-300x179.jpg" alt="" width="548" height="327" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/tech_stack-300x179.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/tech_stack.jpg 739w" sizes="(max-width: 548px) 100vw, 548px" /&gt;&lt;p id="caption-attachment-731717" class="wp-caption-text"&gt;Figure 2. Architectural Overview&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We will use Red Hat Integration for both its event streaming infrastructure and its ability to fulfill the required integration capabilities. The architecture&amp;#8217;s backbone is &lt;a href="https://developers.redhat.com/blog/2019/12/04/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-1/"&gt;Red Hat AMQ Streams&lt;/a&gt;, a massively scalable, distributed, and high-performance data-streaming platform that is based on Apache Kafka.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ll also use the developer preview of &lt;a href="https://developers.redhat.com/blog/2020/01/21/first-steps-with-the-data-virtualization-operator-for-red-hat-openshift/"&gt;Red Hat Data Virtualization&lt;/a&gt;, a container-native service that provides integrated access to diverse data sources. We&amp;#8217;ll use Data Virtualization to collect data from different data sources. We&amp;#8217;ll use the data to create the customer context.&lt;/p&gt; &lt;p&gt;Finally, we&amp;#8217;ll use &lt;a href="https://developers.redhat.com/products/fuse/getting-started"&gt;Red Hat Fuse Online&lt;/a&gt; to create both the integration and the data services. Fuse Online is an Integration Platform-as-a-Service (iPaaS) that makes it easy for business users to collaborate with integration experts and application developers. With Fuse Online&amp;#8217;s low-code tooling, integration experts can quickly create data services and integrations.&lt;/p&gt; &lt;h3&gt;The Integration flow&lt;/h3&gt; &lt;p&gt;Figure 3 shows the sequence of steps required for the example integration.&lt;/p&gt; &lt;div id="attachment_721377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/integ_map.jpeg"&gt;&lt;img aria-describedby="caption-attachment-721377" class="wp-image-721377" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/integ_map-300x36.jpeg" alt="A linear diagram with icons depicting the integration stack." width="640" height="78" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/integ_map-300x36.jpeg 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/integ_map-768x93.jpeg 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/integ_map-1024x124.jpeg 1024w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721377" class="wp-caption-text"&gt;Figure 3. A preview of the complete integration stack.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The integration begins when the system reads an event from a Transaction topic. The system looks up the customer&amp;#8217;s context and Customer Segmentation. The system then applies checks to ensure that only users who meet the required filter criteria will receive an offer. Finally, if the customer is eligible, the system publishes an offer in a secondary Kafka topic.&lt;/p&gt; &lt;h2&gt;Preparing the environment&lt;/h2&gt; &lt;p&gt;Now that you have an overview of the example integration let&amp;#8217;s set up our demonstration environment. We&amp;#8217;ll use &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; to install the components that we need. OpenShift enables efficient container orchestration, allowing developers to rapidly provision, deploy, scale, and manage container-based applications. We&amp;#8217;ll use Red Hat Integration on OpenShift to rapidly and easily create and manage a web-scale cloud-native integration.&lt;/p&gt; &lt;h3&gt;Step 1: Deploy AMQ Streams&lt;/h3&gt; &lt;p&gt;To start, we&amp;#8217;ll install AMQ Streams from the OpenShift OperatorHub. Begin by logging in to the OpenShift console and creating a new project. Figure 4 shows the selection to install the AMQ Streams Operator from the OperatorHub.&lt;/p&gt; &lt;div id="attachment_732527" style="width: 687px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-732527" class="wp-image-732527" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator-300x152.png" alt="" width="677" height="343" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator-768x390.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator-1024x520.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator.png 1600w" sizes="(max-width: 677px) 100vw, 677px" /&gt;&lt;p id="caption-attachment-732527" class="wp-caption-text"&gt;Figure 4. AMQ Streams Operator&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, create a Kafka cluster with the default settings provided by the AMQ Streams Operator, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_732537" style="width: 660px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-732537" class="wp-image-732537" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator_2-300x152.png" alt="" width="650" height="329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator_2-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator_2-768x388.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator_2-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/fuse_online_operator_2.png 1600w" sizes="(max-width: 650px) 100vw, 650px" /&gt;&lt;p id="caption-attachment-732537" class="wp-caption-text"&gt;Figure 5. Kafka Configuration&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You should now have an ephemeral Kafka cluster.&lt;/p&gt; &lt;h3&gt;Step 2: Deploy Fuse Online&lt;/h3&gt; &lt;p&gt;Now we&amp;#8217;ll use the OperatorHub to deploy Fuse Online, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_721407" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_3.png"&gt;&lt;img aria-describedby="caption-attachment-721407" class="wp-image-721407" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_3-300x150.png" alt="A screenshot of Fuse Online in the OpenShift Operator Hub." width="640" height="320" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_3-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_3-768x384.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_3-1024x513.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_3.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721407" class="wp-caption-text"&gt;Figure 6. Fuse Online Operator&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 3: Prepare the data&lt;/h3&gt; &lt;p&gt;The final step before we begin the demo is to create the database tables that will hold our application&amp;#8217;s customer and transaction data. We will need to set up a mock event emitter that would mimic the behavior of real customer events flowing through the system. We will also need to set up a mock endpoint for the prediction service, which we&amp;#8217;ll consume from our integration service. This part of the process is a little more involved, so please follow the &lt;a target="_blank" rel="nofollow" href="https://github.com/snandakumar87/citizen-integrator-story-assets/blob/master/prepare_data.adoc"&gt;steps described here&lt;/a&gt; to complete the setup.&lt;/p&gt; &lt;h2&gt;Low-code tooling with Fuse Online&lt;/h2&gt; &lt;p&gt;Once the infrastructure is set up, we can log in to the Fuse Online console. You can find the URL for the console under the routes. You should be able to log in with your OpenShift console credentials.&lt;/p&gt; &lt;h3&gt;Step 1: Create connections&lt;/h3&gt; &lt;p&gt;First, we&amp;#8217;ll need to set up two connections: one for the PostgreSQL database and the other for MySQL. From Fuse Online&amp;#8217;s &lt;strong&gt;Connections&lt;/strong&gt; tab, click on &lt;strong&gt;Create Connections&lt;/strong&gt; and choose &lt;strong&gt;Database&lt;/strong&gt;, as shown in Figure 7. Setup the connection credentials for the Postgres DB.&lt;/p&gt; &lt;div id="attachment_721417" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_4.png"&gt;&lt;img aria-describedby="caption-attachment-721417" class="wp-image-721417" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_4-300x152.png" alt="A screenshot of the dialog to create a database connection." width="640" height="324" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_4-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_4-768x388.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_4-1024x518.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_4.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721417" class="wp-caption-text"&gt;Figure 7. Create a database connection for PostgreSQL.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Follow the same process to create the connection string for the MySQL database, using the connection parameters shown in Figure 8.&lt;/p&gt; &lt;div id="attachment_721427" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_5.png"&gt;&lt;img aria-describedby="caption-attachment-721427" class="wp-image-721427" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_5-300x148.png" alt="A screenshot of the dialog and parameters for the MySQL connection." width="640" height="316" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_5-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_5-768x380.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_5-1024x506.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_5.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721427" class="wp-caption-text"&gt;Figure 8. Create a database connection for MySQL.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;The Kafka connector&lt;/h4&gt; &lt;p&gt;Next, we&amp;#8217;ll create a Kafka connector so that we can read and publish events to a customer events stream. Choose the &lt;strong&gt;Kafka Message Broker&lt;/strong&gt; connection type under &lt;strong&gt;Create Connections&lt;/strong&gt;, then add the URL of the previously created Kafka cluster, as shown in Figure 9.&lt;/p&gt; &lt;div id="attachment_721437" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_6.png"&gt;&lt;img aria-describedby="caption-attachment-721437" class="wp-image-721437" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_6-300x140.png" alt="A screenshot of the dialog to add the Kafka cluster URL." width="640" height="299" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_6-300x140.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_6-768x359.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_6-1024x479.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_6.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721437" class="wp-caption-text"&gt;Figure 9. Add the URL of the Kafka cluster.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;The API client connection&lt;/h4&gt; &lt;p&gt;Finally, we&amp;#8217;ll set up an API client connection to mock the prediction API. &lt;a target="_blank" rel="nofollow" href="https://github.com/snandakumar87/citizen-integrator-story-assets/blob/master/api_json.json"&gt;Upload this JSON file&lt;/a&gt; to create the prediction-service connector, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_721447" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_7.png"&gt;&lt;img aria-describedby="caption-attachment-721447" class="wp-image-721447" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_7-300x156.png" alt="A screenshot of the dialog to upload the JSON file." width="640" height="332" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_7-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_7-768x399.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_7-1024x532.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_7.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721447" class="wp-caption-text"&gt;Figure 10. Upload the JSON file in the API client connector wizard.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Follow the directions to save the API client connector when you are done.&lt;/p&gt; &lt;p&gt;Now we&amp;#8217;re ready to begin creating the integration. We&amp;#8217;ll start with the data service.&lt;/p&gt; &lt;h3&gt;Step 2: Create the data service&lt;/h3&gt; &lt;p&gt;Start by selecting the &lt;strong&gt;Data&lt;/strong&gt; option from Fuse Online&amp;#8217;s left-hand pane, then click on &lt;strong&gt;Create Data Virtualization&lt;/strong&gt;.&lt;/p&gt; &lt;h4&gt;Create a view&lt;/h4&gt; &lt;p&gt;All of our connections appear in the view editor.  Select the &lt;strong&gt;Transaction&lt;/strong&gt; and &lt;strong&gt;Customer&lt;/strong&gt; tables, as shown in Figure 11.&lt;/p&gt; &lt;div id="attachment_721467" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_8.png"&gt;&lt;img aria-describedby="caption-attachment-721467" class="wp-image-721467" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_8-300x138.png" alt="A screenshot of the dialog to select the required tables." width="640" height="295" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_8-300x138.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_8-768x354.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_8-1024x472.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_8.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721467" class="wp-caption-text"&gt;Figure 11. Select the Transaction and Customer tables.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can also use the view editor to create a &lt;strong&gt;Virtual Database&lt;/strong&gt; table with the consolidated customer context, as shown in Figure 12.&lt;/p&gt; &lt;div id="attachment_721487" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_9.png"&gt;&lt;img aria-describedby="caption-attachment-721487" class="wp-image-721487" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_9-300x152.png" alt="A screenshot of the dialog to create a virtual database table." width="640" height="324" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_9-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_9-768x389.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_9-1024x518.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_online_operator_9.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721487" class="wp-caption-text"&gt;Figure 12. Create a Virtual Database table to host the customer context.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The view editor also provides a data section where we will be able to test the results of a query.&lt;/p&gt; &lt;h4&gt;Publish and access the data service&lt;/h4&gt; &lt;p&gt;Now we are ready to publish the data service. Once it&amp;#8217;s published, we can use either the &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/tutorial/jdbc/basics/index.html"&gt;Java Database Connectivity (JDBC) API&lt;/a&gt; or an &lt;a target="_blank" rel="nofollow" href="https://www.odata.org"&gt;OData endpoint&lt;/a&gt; to access the virtual database. Select the OData endpoint, as shown in Figure 13.&lt;/p&gt; &lt;div id="attachment_721497" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_1.png"&gt;&lt;img aria-describedby="caption-attachment-721497" class="wp-image-721497" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_1-300x71.png" alt="A screenshot of the dialog to select the OData endpoint." width="640" height="152" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_1-300x71.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_1-768x182.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_1-1024x243.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_1.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721497" class="wp-caption-text"&gt;Figure 13. Select the OData endpoint to access the virtual database.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As shown in Figure 14, we can use the URL format &lt;strong&gt;&amp;#60;odata-link&amp;#62;/odata/&amp;#60;virtualization-name&amp;#62;/&amp;#60;view-name&amp;#62; &lt;/strong&gt;to access the OData endpoint.&lt;/p&gt; &lt;div id="attachment_721507" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_2.png"&gt;&lt;img aria-describedby="caption-attachment-721507" class="wp-image-721507" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_2-300x97.png" alt="A screenshot of the URL format to access the virtual database." width="640" height="206" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_2-300x97.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_2-768x248.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_2-1024x330.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_2.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721507" class="wp-caption-text"&gt;Figure 14. Access the virtual database via its OData endpoint.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 3: Create the integration service&lt;/h3&gt; &lt;p&gt;Now we&amp;#8217;ll create an integration service.&lt;/p&gt; &lt;h4&gt;Subscribe and Publish to Kafka&lt;/h4&gt; &lt;p&gt;In the Fuse Online console, go to the &lt;strong&gt;Integration&lt;/strong&gt; tab and click &lt;strong&gt;Create Integration&lt;/strong&gt;. As shown in Figure 15, we can read from the Kafka topic where customer events are created.&lt;/p&gt; &lt;div id="attachment_721517" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_3.png"&gt;&lt;img aria-describedby="caption-attachment-721517" class="wp-image-721517" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_3-300x107.png" alt="A screenshot of the dialog to configure a customer event." width="640" height="227" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_3-300x107.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_3-768x273.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_3-1024x364.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_3.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721517" class="wp-caption-text"&gt;Figure 15. Configure the Kafka Subscribe Step.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We&amp;#8217;ll use a JSON instance to define the message&amp;#8217;s data structure:&lt;/p&gt; &lt;pre&gt;{"eventValue": "MERCHANDISE", "eventSource": "POS","custId":"CUST898920"} &lt;/pre&gt; &lt;p&gt;As shown in Figure 16, we&amp;#8217;ll define the integration&amp;#8217;s last step, where we&amp;#8217;ll write the offer results back to a Kafka topic. We will define the JSON instance for the customer&amp;#8217;s offer data, as follows:&lt;/p&gt; &lt;pre&gt;{"offer": "value", "custId":"id","customerClass":"class","customersegmentation":"segment"} &lt;/pre&gt; &lt;div id="attachment_721527" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_4.png"&gt;&lt;img aria-describedby="caption-attachment-721527" class="wp-image-721527" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_4-300x133.png" alt="A screenshot showing the option to configure the endpoint for a Kafka event." width="640" height="283" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_4-300x133.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_4-768x339.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_4-1024x452.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_4.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721527" class="wp-caption-text"&gt;Figure 16. Configure the Kafka Publish Step.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Fetch the customer data&lt;/h4&gt; &lt;p&gt;Next, we fetch our customer data from the virtual database. In the Fuse Online console, select the &lt;strong&gt;Virtual DB&lt;/strong&gt; connection that we configured earlier, then choose the &lt;strong&gt;Invoke SQL&lt;/strong&gt; option.&lt;/p&gt; &lt;p&gt;Next, we&amp;#8217;ll define intermediate steps before reaching that endpoint. For every customer record, we will fetch the customer&amp;#8217;s virtual data context, which we created earlier. Figure 17 shows the dialog to fetch the virtual data context.&lt;/p&gt; &lt;div id="attachment_721537" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_6.png"&gt;&lt;img aria-describedby="caption-attachment-721537" class="wp-image-721537" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_6-300x136.png" alt="A screenshot of the dialog to create the Kafka event and the option to fetch the virtual data context." width="640" height="290" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_6-300x136.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_6-768x348.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_6-1024x463.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_6.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721537" class="wp-caption-text"&gt;Figure 17. Fetch the virtual data context.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 18 is a screenshot of how the integration looks so far.&lt;/p&gt; &lt;div id="attachment_721547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_7.png"&gt;&lt;img aria-describedby="caption-attachment-721547" class="wp-image-721547" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_7-300x117.png" alt="The dialog shows the integration with steps added so far and the option to add more steps." width="640" height="250" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_7-300x117.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_7-768x300.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_7-1024x401.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_7.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721547" class="wp-caption-text"&gt;Figure 18. A screenshot of the integration in progress.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Fetch the prediction data&lt;/h4&gt; &lt;p&gt;Next, we&amp;#8217;ll add a step to fetch the prediction data from our mock prediction service. Click on the plus (+) symbol after Step 2 and choose the prediction-service connection that we created earlier. This step is shown in Figure 19.&lt;/p&gt; &lt;div id="attachment_721557" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_8.png"&gt;&lt;img aria-describedby="caption-attachment-721557" class="wp-image-721557" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_8-300x85.png" alt="A screenshot of the dialog to add the prediction text." width="640" height="180" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_8-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_8-768x216.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_8-1024x289.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_8.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721557" class="wp-caption-text"&gt;Figure 19. Fetch the prediction data.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Define a data mapper for each connection&lt;/h4&gt; &lt;p&gt;After each of the connection steps, you will now see a warning to define the data mapper. The data mapper maps a customer&amp;#8217;s input values to the correct output values.  To start defining the data mappers, click on the plus (+) symbol immediately after Step 1. As shown in Figure 20, this will give you the option to define the target step.&lt;/p&gt; &lt;div id="attachment_721577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_9.png"&gt;&lt;img aria-describedby="caption-attachment-721577" class="wp-image-721577" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_9-300x121.png" alt="A screenshot of the dialog to map to the correct database." width="640" height="258" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_9-300x121.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_9-768x310.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_9-1024x413.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_9.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721577" class="wp-caption-text"&gt;Figure 20. Mapping the Source and Target steps.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Follow the same process to define the mapper that will be called when we invoke the prediction service, and then the mapper that will be called before we publish to the Kafka topic.&lt;/p&gt; &lt;p&gt;As shown in Figure 21, we use the data-mapper dialog to map the values from each of the steps so that we can select the correct offer for the customer. Also, note that we are using this dialog to add a transformation to the offer text.&lt;/p&gt; &lt;div id="attachment_721587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_10.png"&gt;&lt;img aria-describedby="caption-attachment-721587" class="wp-image-721587" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_10-300x146.png" alt="A screenshot of the dialog to map the values of each step." width="640" height="311" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_10-300x146.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_10-768x373.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_10-1024x498.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_10.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721587" class="wp-caption-text"&gt;Figure 21. Mapper before publish.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 4: Apply the filter criteria&lt;/h3&gt; &lt;p&gt;We&amp;#8217;ve used Fuse Online to connect all the pieces of our integration. However, you might have noticed that we are missing an important piece. Before we can publish our integration, we need to ensure that we will only extend an offer to customers who have a PLATINUM or GOLD status, and whose predictive loyalty segmentation is labeled either HIGH and MEDIUM. For this, we will configure the &lt;strong&gt;Basic Filter&lt;/strong&gt; option shown in Figure 22.&lt;/p&gt; &lt;div id="attachment_721597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_11.png"&gt;&lt;img aria-describedby="caption-attachment-721597" class="wp-image-721597" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_11-300x152.png" alt="A screenshot of the dialog selecting the basic-filter option." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_11-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_11-768x388.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_11-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_11.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721597" class="wp-caption-text"&gt;Figure 22. Configure the Basic Filter option for customer status and predictive loyalty segmentation.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 5: Publish and monitor the integration&lt;/h3&gt; &lt;p&gt;Now that we are done assembling all of the pieces, it is time to publish. Just save the integration and publish it. After it is published, the integration stack should look like what you see in Figure 23.&lt;/p&gt; &lt;div id="attachment_721607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_12.png"&gt;&lt;img aria-describedby="caption-attachment-721607" class="wp-image-721607" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_12-300x77.png" alt="" width="640" height="163" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_12-300x77.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_12-768x196.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_12-1024x261.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_12.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721607" class="wp-caption-text"&gt;Figure 23. The complete stack for the Loyalty Management Application.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Monitor the integration&lt;/h4&gt; &lt;p&gt;We can use the &lt;strong&gt;Activity&lt;/strong&gt; tab to view events as they are being processed, as shown in Figure 24.&lt;/p&gt; &lt;div id="attachment_721617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_13.png"&gt;&lt;img aria-describedby="caption-attachment-721617" class="wp-image-721617" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_13-300x148.png" alt="A screenshot of the Activity tab." width="640" height="315" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_13-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_13-768x378.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_13-1024x504.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_13.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721617" class="wp-caption-text"&gt;Figure 24. Use the Activity tab to view events as they are being processed.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can use the &lt;strong&gt;Metrics&lt;/strong&gt; tab to view the overall metrics for processed messages, as shown in Figure 25.&lt;/p&gt; &lt;div id="attachment_721627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_14.png"&gt;&lt;img aria-describedby="caption-attachment-721627" class="wp-image-721627" src="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_14-300x80.png" alt="A screenshot of the Metrics tab." width="640" height="171" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_14-300x80.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_14-768x205.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_14-1024x273.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/05/fuse_onliner_14.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-721627" class="wp-caption-text"&gt;Figure 25. Use the Metrics tab to view the overall metrics for received and processed Kafka messages.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Visit my GitHub repository to &lt;a target="_blank" rel="nofollow" href="https://github.com/snandakumar87/citizen-integrator-story-assets/blob/master/portfolio-integration-export.zip"&gt;download the complete integration code&lt;/a&gt;. If you want to import the code to Fuse Online, navigate to the &lt;strong&gt;Integration&lt;/strong&gt; tab, and click &lt;strong&gt;Import&lt;/strong&gt;.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Using the data-first approach, we are now able to quickly visualize the context information required for our near real-time processing requirements. By providing low code tooling we are able to empower the citizen integrators and data experts to quickly create these integration solutions in a cloud-native fashion. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#38;linkname=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fevent-streaming-and-data-federation-a-citizen-integrators-story%2F&amp;#038;title=Event%20streaming%20and%20data%20federation%3A%20A%20citizen%20integrator%E2%80%99s%20story" data-a2a-url="https://developers.redhat.com/blog/2020/06/12/event-streaming-and-data-federation-a-citizen-integrators-story/" data-a2a-title="Event streaming and data federation: A citizen integrator’s story"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/12/event-streaming-and-data-federation-a-citizen-integrators-story/"&gt;Event streaming and data federation: A citizen integrator&amp;#8217;s story&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3vF8QZhP7kA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Businesses are seeking to benefit from every customer interaction with real-time personalized experience. Targeting each customer with relevant offers can greatly improve customer loyalty, but we must first understand the customer. We have to be able to draw on data and other resources from diverse systems, such as marketing, customer service, fraud, and business operations. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/12/event-streaming-and-data-federation-a-citizen-integrators-story/"&gt;Event streaming and data federation: A citizen integrator&amp;#8217;s story&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">721337</post-id><dc:creator>snandaku</dc:creator><dc:date>2020-06-12T07:00:33Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/12/event-streaming-and-data-federation-a-citizen-integrators-story/</feedburner:origLink></entry><entry><title>How to install CodeReady Workspaces in a restricted OpenShift 4 environment</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/H1rPmYaIm6g/" /><category term="Developer Tools" /><category term="Java" /><category term="Operator" /><category term="Universal Base Images (UBI)" /><category term="air gapped" /><category term="Eclipse Che" /><category term="Enterprise Java" /><category term="openshift" /><category term="pull image" /><author><name>Bryant Son</name></author><id>https://developers.redhat.com/blog/?p=657467</id><updated>2020-06-12T07:00:04Z</updated><published>2020-06-12T07:00:04Z</published><content type="html">&lt;p&gt;It&amp;#8217;s your first day as a &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; programmer, right out of college. You have received your badge, a shiny new laptop, and all of your software requests have been approved. Everything seems to be going well.&lt;/p&gt; &lt;p&gt;You install Eclipse and set up the required Java Development Kit (JDK) in your new development environment. You clone a project from the company&amp;#8217;s GitHub repository, modify the code, and make your first commit. You are excited to be working on your first project.&lt;/p&gt; &lt;p&gt;But then, a few hours later, a senior programmer asks what version of the JDK you used. It seems that the pipeline is reporting a project failure. All you did was commit Java source code, not binary, and it worked perfectly on your local machine. What could possibly have gone wrong?&lt;/p&gt; &lt;h2&gt;Coding in a restricted environment&lt;/h2&gt; &lt;p&gt;The issue I described is well-known among programmers as the &amp;#8220;&lt;a target="_blank" rel="nofollow" href="https://imgs.xkcd.com/comics/inexplicable.png"&gt;It works on my computer, and I don&amp;#8217;t know why it doesn&amp;#8217;t work on your computer&lt;/a&gt;&amp;#8221; problem. Fortunately, this is the type of problem &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces (CRW)&lt;/a&gt; can help you solve. CodeReady Workspaces is a cloud-based IDE based on &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/che"&gt;Che&lt;/a&gt;. Whereas Che is an open source project, CRW is an enterprise-ready development environment that provides the security, stability, and consistency that many corporations require. All you have to do is open the CRW link in a web browser, sign in with your user credentials, and code inside the browser.&lt;/p&gt; &lt;p&gt;In this article, I show you how to install CodeReady Workspaces in a restricted &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift 4&lt;/a&gt; environment.&lt;/p&gt; &lt;p&gt;&lt;span id="more-657467"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Example setup and prerequisites&lt;/h2&gt; &lt;p&gt;Ideally, you should be able to pull images directly from the &lt;a target="_blank" rel="nofollow" href="https://catalog.redhat.com/software/containers/explore"&gt;Red Hat Registry&lt;/a&gt; and use them for your installation. After all, images in the Red Hat Registry are secure and certified. In some cases, however, you will find that the company’s network is behind a firewall, or that the network policy does not allow you to pull images directly from the Red Hat Registry. For this article, I assume that you can neither pull images nor enable a proxy to pull images directly from the Red Hat Registry. Instead, I show you how to pull the required images and stash them in the company&amp;#8217;s private registry, such as Artifactory or Nexus. You can then use the privately stored images to install CodeReady Workspaces.&lt;/p&gt; &lt;p&gt;I assume the following about your environment and the installation process:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;The cloud platform is OpenShift 4&lt;/strong&gt;: You should have a running OpenShift 4 environment, and you should know how to use the OpenShift user interface (UI) or command-line interface (CLI).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;We&amp;#8217;re installing CodeReady Workspaces version 2.0 or higher&lt;/strong&gt;: Most of this tutorial is applicable to CRW 1.2, but I assume that you are using at least CodeReady Workspaces 2.0.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;We will use OpenShift 4&amp;#8217;s OperatorHub for installation&lt;/strong&gt;: You could use another method to install CodeReady Workspaces, but I will demonstrate how to use OpenShift 4&amp;#8217;s built-in OperatorHub.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The environment is a restricted network&lt;/strong&gt;: Although you could set up the example in a non-restricted environment, I assume that you are working in a restricted network.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;You have access to the Red Hat Registry&lt;/strong&gt;: You should be able to log in and retrieve container images from the Red Hat Registry.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;You have access to a private registry&lt;/strong&gt;: After you pull container images from the Red Hat Registry, you need to store them in a private registry, such as Artifactory or Nexus.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Note that my example is also based on an &lt;i&gt;air-gapped installation&lt;/i&gt;, which is a disconnected installation that supports working in a restricted environment.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s get started.&lt;/p&gt; &lt;h2&gt;Step 1: Pull the required CRW images from the Red Hat Registry&lt;/h2&gt; &lt;p&gt;Installing CRW 2.0 in a restricted environment requires pulling 13 images from the &lt;a target="_blank" rel="nofollow" href="https://catalog.redhat.com/software/containers/explore"&gt;Red Hat Container Registry&lt;/a&gt;, which is shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_656707" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656707" class="wp-image-656707 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-19-at-8.58.58-PM-1024x497.png" alt="A screenshot of installation images for CodeReady Workshop in the Red Hat Container Registry." width="640" height="311" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-19-at-8.58.58-PM-1024x497.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-19-at-8.58.58-PM-300x146.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-19-at-8.58.58-PM-768x373.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656707" class="wp-caption-text"&gt;Figure 1. Find the required images for your CodeReady Workshop installation in the Red Hat Container Registry.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The first five images have been required since CodeReady Workspaces 1.2, and the eight new images are required to deploy CRW 2.0:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;code&gt;codeready-workspaces/server-operator-rhel8:2.0&lt;/code&gt;: The CodeReady Workspaces Operator orchestrates and manages the installation process. It is especially important to have this Operator installed for OpenShift 4.x.&lt;/li&gt; &lt;li&gt;&lt;code&gt;codeready-workspaces/server-rhel8:2.0&lt;/code&gt;: This is the Che server. It provides the main platform to manage workspaces and aspects of the project, such as programming stacks, user groups, and the factory. You will also use the Che server to view your project dashboard.&lt;/li&gt; &lt;li&gt;&lt;code&gt;redhat-sso-7/sso73-openshift:latest&lt;/code&gt;: CRW uses Red Hat Single Sign-On (SSO), which is based on &lt;a target="_blank" rel="nofollow" href="https://www.keycloak.org/"&gt;Keycloak&lt;/a&gt;. This enterprise implementation is compliant with SAML 2.0 and OpenID. You will need it to authenticate, authorize, and manage users in CodeReady Workspaces.&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Factory is JavaScript Object Notation (JSON) file that defines the elements, including where to find the source code for the workspace, what languages are used in the project, the commands to pre-populate in the IDE for the workspaces, as well as any post-load actions to be performed on the workspace automatically after it is built.&lt;/p&gt; &lt;ol start="4"&gt; &lt;li&gt;&lt;code&gt;rhscl/postgresql-96-rhel7:latest&lt;/code&gt;: Keycloak writes to the PostgreSQL database. You will need this image to store user-related data.&lt;/li&gt; &lt;li&gt;&lt;code&gt;ubi8-minimal:latest&lt;/code&gt;: The universal base image (UBI) provides the persistent volume that you will use to store data for your workspace and anything else that is required for CRW.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;You also need to import the following images:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/pluginregistry-rhel8:2.0&lt;/code&gt;: Makes it possible to share a plug-in definition across all the users of the same instance of CodeReady Workspaces. Only plug-ins that are published in a registry can be used in a devfile.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/devfileregistry-rhel8:2.0&lt;/code&gt;: Holds the definitions of the CodeReady Workspaces stacks. These are available on the CodeReady Workspaces user dashboard when selecting &lt;strong&gt;Create Workspace&lt;/strong&gt;. It contains the list of CodeReady Workspaces technological stack samples with example projects.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/pluginbroker-rhel8:2.0&lt;/code&gt;: Ensures via this Operator that all installed plug-ins are handled correctly.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/pluginbrokerinit:2.0&lt;/code&gt;: Runs as an init container to ensure that all installed plugins are handled correctly.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/jwtproxy-rhel8:2.0&lt;/code&gt;: Implements the self-signed per-workspace JWT token and its verification on a dedicated service based on JWT proxy.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/machineexec-rhel8:2.0&lt;/code&gt;: Runs Go-lang server-side creation for machine-execs for CRW workspaces.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/theia-rhel8:2.0&lt;/code&gt;: Defines the default web IDE for the workspace based on &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse-theia/theia"&gt;the Theia project&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;registry.redhat.io/codeready-workspaces/theia-endpoint-rhel8:2.0&lt;/code&gt;: Similar to the theia-rhel8 image above, this adds the Theia components for CRW&amp;#8217;s IDE look and feel.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;From CRW 2.1, there seems to be significant updates to the required images listed above. For example:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;codeready-workspaces/server-operator-rhel8:2.0&lt;/code&gt; is gone and replaced with &lt;code&gt;codeready-workspaces/crw-2-rhel8-operator:2.1&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;pluginbroker-rhel8&lt;/code&gt; and &lt;code&gt;pluginbrokerinit:2.0&lt;/code&gt; are replaced with &lt;code&gt;codeready-workspaces/pluginbroker-artifacts-rhel8:2.1&lt;/code&gt; and &lt;code&gt;codeready-workspaces/pluginbroker-metadata-rhel8:2.1&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;theia-dev-rhel8:2.1&lt;/code&gt; was added to the list of images.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you end up using CRW 2.1, please make the appropriate changes.&lt;/p&gt; &lt;h3&gt;Download the images&lt;/h3&gt; &lt;p&gt;When you locate a container image that you need, select the image, and click the &lt;strong&gt;Tags&lt;/strong&gt; tab to see the image name and version information. You will specify this information later, to pull the images from the Red Hat Container Registry. As of this writing, the version number for the CodeReady Workspaces Operator is 2.0, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_660557" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-660557" class="wp-image-660557 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-4.30.03-PM-1024x626.png" alt="A screenshot showing the CodeReady Workspaces Operator image in the Red Hat Container Registry." width="640" height="391" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-4.30.03-PM-1024x626.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-4.30.03-PM-300x183.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-4.30.03-PM-768x470.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-660557" class="wp-caption-text"&gt;Figure 2. Locate the CodeReady Workspaces Operator in the Red Hat Container Registry.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Unless you have access to a common service account or another authentication mechanism, you will need to create an account before you can download images from the registry. Open the &lt;strong&gt;Get This Image&lt;/strong&gt; tab shown in Figure 3 and follow the detailed instructions.&lt;/p&gt; &lt;div id="attachment_657507" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657507" class="wp-image-657507 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-20-at-10.52.50-PM-1024x627.png" alt="A screenshot of the dialog to create a Red Hat Registry service account." width="640" height="392" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-20-at-10.52.50-PM-1024x627.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-20-at-10.52.50-PM-300x184.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-20-at-10.52.50-PM-768x471.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657507" class="wp-caption-text"&gt;Figure 3. Create a service account for the Red Hat Registry.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Each private registry has its own approach to pulling images and storing them. For Artifactory, you could use something like the following &lt;code&gt;curl&lt;/code&gt; command, which you would update with your own variable values:&lt;/p&gt; &lt;pre&gt;$ curl -u JFROG_USERNAME:JFROG_PASSWORD ARTIFACTORY_URL/IMAGE_NAME/metadata/IMAGE_VERSION -k &lt;/pre&gt; &lt;p&gt;Follow the instructions specified by your registry, as well as any requirements that are particular to your organization.&lt;/p&gt; &lt;h3&gt;Verify the images&lt;/h3&gt; &lt;p&gt;Once you pull the images from the Red Hat Registry, verify that they are stored in your private registry. Figure 4 is a screenshot of my Artifactory registry, where I stored the images required for my CodeReady Workspaces installation.&lt;/p&gt; &lt;div id="attachment_657027" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657027" class="wp-image-657027 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/artifactory_screen-1024x667.png" alt="A screenshot of the Artifactory console showing the images that are required to install CodeReady Workspaces." width="640" height="417" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/artifactory_screen-1024x667.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/artifactory_screen-300x196.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/artifactory_screen-768x500.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657027" class="wp-caption-text"&gt;Figure 4. Find the CodeReady Workspaces images stored in Artifactory.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The images that I have outlined in red are required to install CodeReady Workspaces. Use the latest versions available from the Red Hat Registry. The images outlined in blue are &lt;em&gt;stacks&lt;/em&gt;, which represent different programming runtimes. Stacks aren&amp;#8217;t required for your CRW installation, but you will use them in conjunction with a &lt;code&gt;devfile&lt;/code&gt; to create new projects. I will introduce you to the process of importing stacks in Part 2. The image outlined in green (in the upper-right corner of the screenshot) is a package name.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Currently, only OpenShift 4 supports the CodeReady Workspaces Operator, which is key to the installation described in this article. While you could theoretically install CodeReady Workspaces in Kubernetes, I assume that you are installing on OpenShift 4.&lt;/p&gt; &lt;h2&gt;Step 2: Create a new OpenShift 4 project&lt;/h2&gt; &lt;p&gt;Creating a new project in OpenShift is the same whether you are using OpenShift 3 or OpenShift 4. Either way, you can use the OpenShift user interface (UI) or the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.2/cli_reference/openshift_cli/getting-started-cli.html"&gt;OpenShift command-line interface (CLI)&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Creating a new project with the OpenShift UI&lt;/h3&gt; &lt;p&gt;The OpenShift UI is easy to use. Click &lt;strong&gt;Create Project&lt;/strong&gt; and enter your project information in the remaining fields. Note that you only need to specify the project name. OpenShift uses this information to create a namespace. In the project dialog shown in Figure 5, I entered the project name: &lt;code&gt;crw-demo&lt;/code&gt;.&lt;/p&gt; &lt;div id="attachment_657447" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657447" class="wp-image-657447 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/crw_creation-1-1024x370.jpg" alt="A screenshot showing the dialog to create a new OpenShift project." width="640" height="231" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/crw_creation-1-1024x370.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/crw_creation-1-300x108.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/crw_creation-1-768x277.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/crw_creation-1.jpg 1288w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657447" class="wp-caption-text"&gt;Figure 5. Create a new OpenShift project.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Creating a new project with the OpenShift CLI&lt;/h3&gt; &lt;p&gt;Your other option is to use the OpenShift Container Platform (OCP) CLI. In this case, you would open the command line and enter the command &lt;code&gt;oc new-project&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ oc new-project crw-demo &lt;/pre&gt; &lt;p&gt;Once again, I named my new project &lt;code&gt;crw-demo&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When you create a new project, OpenShift creates new resources for the project, including two service accounts that you will use later. These are named &lt;strong&gt;default&lt;/strong&gt; and &lt;strong&gt;builder&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Next, we&amp;#8217;ll generate an access token and add it to your OpenShift secrets. You will need this token to pull images from your private registry.&lt;/p&gt; &lt;h2&gt;Step 3: Generate an access token and add it to OpenShift secrets&lt;/h2&gt; &lt;p&gt;The diagram in Figure 6 shows the general process for generating an access token, which you&amp;#8217;ll use to authenticate your user ID and gain access to your private registry. The actual process will vary depending on the application, policy, and environment.&lt;/p&gt; &lt;div id="attachment_657017" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657017" class="wp-image-657017 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/2_diagram_token-1024x561.jpg" alt="A screenshot showing the dialog to create an OpenShift secret." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/2_diagram_token-1024x561.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/2_diagram_token-300x164.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/2_diagram_token-768x421.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/2_diagram_token.jpg 1500w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657017" class="wp-caption-text"&gt;Figure 6. Create an OpenShift secret, which you will use to authenticate your ID in the private registry.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Authorization consists of four steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Request an access token from a service such as &lt;a target="_blank" rel="nofollow" href="https://oauth.net"&gt;OAuth&lt;/a&gt;. The service will generate the token and send it to the private registry. (In some cases you might use a proxy to request the token.)&lt;/li&gt; &lt;li&gt;Call into the private registry and retrieve the token.&lt;/li&gt; &lt;li&gt;Use the token to create an OpenShift secret as a Docker registry.&lt;/li&gt; &lt;li&gt;Add the OpenShift secret containing the token to each of your service accounts in CodeReady Workspaces. (The CodeReady Workspaces Operator requires various service accounts for installation. I&amp;#8217;ll explain this further shortly.)&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: In some environments, the process of generating and authenticating the token is done by a developer, whereas in others it is facilitated by a proxy. Either way, it is essential to select a token that does not expire. Another option would be to use a tool like &lt;a target="_blank" rel="nofollow" href="https://www.vaultproject.io"&gt;Vault&lt;/a&gt; to rotate the token and refresh OpenShift&amp;#8217;s secret mechanism. Describing that process is beyond the scope of this article.&lt;/p&gt; &lt;h3&gt;Generating the token manually&lt;/h3&gt; &lt;p&gt;If you are manually generating the access token, you could use a &lt;code&gt;curl&lt;/code&gt; command as simple as this:&lt;/p&gt; &lt;pre&gt;$ curl -u PRIVATE_REGISTRY_USERNAME:PRIVATE_REGISTRY_PASSWORD -X POST PRIVATE_REGISTRY_TOKEN_URL &lt;/pre&gt; &lt;p&gt;Where:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;PRIVATE_REGISTRY_USERNAME&lt;/code&gt; is your user name to log in to the private registry.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PRIVATE_REGISTRY_PASSWORD&lt;/code&gt; is your password to log in to the private registry.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PRIVATE_REGISTRY_URL&lt;/code&gt; is the web address to generate the access token from the private registry.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Again, the mechanism will vary depending on your environment and other factors. Check the documentation for your private registry or seek advice from your team before attempting to generate an access token.&lt;/p&gt; &lt;h3&gt;Creating the OpenShift secret&lt;/h3&gt; &lt;p&gt;Once you generate the token, you can create an OpenShift secret to store the token in a Docker registry. For this, you would use the &lt;code&gt;create secret&lt;/code&gt; command on the OC CLI:&lt;/p&gt; &lt;pre&gt;$ oc create secret docker-registry PULL_SECRET_NAME --docker-server=URL_IMAGE_PRIVATE_REGISTRY \ --docker-username=USERNAME_PRIVATE_REGISTRY \ --docker-password=TOKEN_PRIVATE_REGISTRY \ --docker-email=EMAIL_PRIVATE_REGISTRY &lt;/pre&gt; &lt;p&gt;Where:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;PULL_SECRET_NAME&lt;/code&gt; is the OpenShift secret name.&lt;/li&gt; &lt;li&gt;&lt;code&gt;URL_IMAGE_PRIVATE_REGISTRY&lt;/code&gt; is the private registry path containing the images you want to pull.&lt;/li&gt; &lt;li&gt;&lt;code&gt;USERNAME_PRIVATE_REGISTRY&lt;/code&gt; is your user name for accessing the private registry.&lt;/li&gt; &lt;li&gt;&lt;code&gt;TOKEN_PRIVATE_REGISTRY&lt;/code&gt; is the private registry token you have just generated.&lt;/li&gt; &lt;li&gt;&lt;code&gt;EMAIL_PRIVATE_REGISTRY&lt;/code&gt; is the email you have associated with the private registry.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In Figure 7, you can see that my token, &lt;strong&gt;artif-ocp4-sec&lt;/strong&gt;, is stored as an OpenShift secret.&lt;/p&gt; &lt;div id="attachment_657907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-657907" class="wp-image-657907 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/secret1-1024x586.jpg" alt="A screenshot of the OpenShift Secrets dashboard showing stored tokens." width="640" height="366" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/secret1-1024x586.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/secret1-300x172.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/secret1-768x439.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/secret1.jpg 1288w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-657907" class="wp-caption-text"&gt;Figure 7. Find your private-registry token stored as an OpenShift secret.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;With that, you have now created an Openshift secret with the credentials necessary to pull the image from your private registry. You still need to link the OpenShift secret to your service accounts. Before I show you how to do that, you must install CodeReady Workspaces.&lt;/p&gt; &lt;h2&gt;Step 4: Use the OpenShift OperatorHub to install CodeReady Workspaces&lt;/h2&gt; &lt;p&gt;One way to install CodeReady Workspaces is to leverage &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/che-incubator/chectl"&gt;chectl&lt;/a&gt;&lt;/code&gt;, which is Che&amp;#8217;s command-line interface. Another way, available starting with OpenShift 4, is to use the OpenShift OperatorHub. Figure 8 shows the dialog to locate and install the CodeReady Workspaces Operator from the OperatorHub. (Note that the OperatorHub also contains the Che Operator.)&lt;/p&gt; &lt;div id="attachment_656777" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656777" class="wp-image-656777 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.00-PM-1024x556.png" alt="A screenshot of CodeReady Workspaces Operator stored in the OpenShift Operator Hub." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.00-PM-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.00-PM-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.00-PM-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656777" class="wp-caption-text"&gt;Figure 8. Find the CodeReady Workspaces Operator in the OpenShift Operator Hub.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you don&amp;#8217;t see the CodeReady Workspaces Operator in your OperatorHub, check the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.3/html/operators/olm-adding-operators-to-a-cluster#olm-installing-operators-from-operatorhub_olm-adding-operators-to-a-cluster"&gt;Operator installation instructions&lt;/a&gt; in the Red Hat OpenShift 4.3 documentation.&lt;/p&gt; &lt;h3&gt;Installing CRW from the OperatorHub&lt;/h3&gt; &lt;p&gt;If you go to the OpenShift OperatorHub and select the CodeReady Workspaces Operator, you should see an option to install it. Before pressing the &lt;strong&gt;Install&lt;/strong&gt; button, as shown in Figure 9, make a note of the CRW Operator version (currently 2.0) and the location of the container image. By default, the location points to &lt;strong&gt;registry.redhat.io&lt;/strong&gt;. Later, you will change this location to point to your private registry.&lt;/p&gt; &lt;div id="attachment_656897" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656897" class="wp-image-656897 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.17-PM-1024x561.png" alt="A screenshot of the option to install the CodeReady Workspaces Operator." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.17-PM-1024x561.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.17-PM-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.17-PM-768x420.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656897" class="wp-caption-text"&gt;Figure 9. Install the CodeReady Workspaces Operator from the OpenShift Operator Hub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After clicking &lt;strong&gt;Install&lt;/strong&gt;, you will be asked to create an Operator subscription. Make sure that you are in the correct namespace. Click the &lt;strong&gt;Subscribe&lt;/strong&gt; button to subscribe to CodeReady Workspaces Operator, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_656907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656907" class="size-large wp-image-656907" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.36-PM-1024x562.png" alt="A screenshot of the option to create a subscription for the CodeReady Workspaces Operator." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.36-PM-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.36-PM-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.36-PM-768x421.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656907" class="wp-caption-text"&gt;Figure 10. Create a subscription for the CodeReady Workspaces Operator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The installation can take a while, so be patient. Once the installation is complete, click the &lt;strong&gt;CodeReady Workspaces Operator&lt;/strong&gt; link to open your new CRW instance, which is shown in Figure 11.&lt;/p&gt; &lt;div id="attachment_656927" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656927" class="size-large wp-image-656927" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.54-PM-1024x556.png" alt="A screenshot of the new CodeReady Workspaces Operator instance stored in our demo project namespace." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.54-PM-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.54-PM-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-09-17-at-12.25.54-PM-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656927" class="wp-caption-text"&gt;Figure 11. Find the CodeReady Workspaces Operator installed in your project namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we&amp;#8217;ll set up a CRW cluster.&lt;/p&gt; &lt;h2&gt;Step 5: Modify CRW&amp;#8217;s custom resource definition file&lt;/h2&gt; &lt;p&gt;So far, you might wonder what about this CRW installation is unique to working in a restricted environment. That will change with this step, where we first create a new CodeReady Workspaces cluster, then modify CRW&amp;#8217;s custom resource definition (CRD) file.&lt;/p&gt; &lt;p&gt;From the CRW project namespace page shown in Figure 11, click the link for your new CodeReady Workspaces Operator. You will be presented with an option to create a new instance of a Red Hat CodeReady Workspaces cluster. Click the &lt;strong&gt;Create Instance&lt;/strong&gt; option, which is shown in Figure 12.&lt;/p&gt; &lt;div id="attachment_658377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658377" class="size-large wp-image-658377" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster1-1024x687.jpg" alt="A screenshot of the option to create a new CodeReady Workspaces cluster." width="640" height="429" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster1-1024x687.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster1-300x201.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster1-768x515.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster1.jpg 1496w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658377" class="wp-caption-text"&gt;Figure 12. Create a new CodeReady Workspaces Operator cluster.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, you will be provided with the custom resource definition file for your CodeReady Workspaces Operator. You will need to customize this file, shown in Figure 13, before installing CRW to OpenShift.&lt;/p&gt; &lt;div id="attachment_658387" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658387" class="size-large wp-image-658387" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster2-1024x853.jpg" alt="A screenshot of the custom resource definition file in YAML." width="640" height="533" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster2-1024x853.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster2-300x250.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/create_cluster2-768x640.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658387" class="wp-caption-text"&gt;Figure 13. The custom resource definition file in YAML format.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The CRD definition is in YAML format, but note that a section of the file is formatted using JSON. You will modify the properties to include the following seven images, which we pulled from the Red Hat Registry in Step 1:&lt;/p&gt; &lt;pre&gt;codeready-workspaces/server-operator-rhel8:2.0 cheImage: codeready-workspaces/server-rhel8:2.0 identityProviderImage: redhat-sso-7/sso73-openshift:latest postgresImage: rhscl/postgresql-96-rhel7:latest pvcJobsImage: ubi8-minimal:latest devfileRegistryImage: codeready-workspaces/devfileregistry-rhel8:2.0 pluginRegistryImage: codeready-workspaces/pluginregistry-rhel8:2.0 &lt;/pre&gt; &lt;p&gt;You can find the full CRD file for the Che Operator on the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/che-operator/blob/master/deploy/crds/org_v1_che_cr.yaml"&gt;Che Operator&amp;#8217;s GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Updating the CRD file&lt;/h3&gt; &lt;p&gt;Note that &lt;code&gt;codeready-workspaces/server-operator-rhel8:2.0&lt;/code&gt; is referenced twice in the CRD file. You will need to add the other images as new properties, as shown in this example:&lt;/p&gt; &lt;pre&gt;"spec": { "server": { ... // Other Properties, # server image used in Che deployment "cheImage": "" }, "database": { ... // Other Properties, "postgresImage": "" }, "storage": { ... // Other Properties, "pvcJobsImage": "" }, "auth": { ... // Other Properties, "identityProviderImage": "" } &lt;/pre&gt; &lt;p&gt;You can also change other properties in this file. For example, I had to change the following two properties to true when I deployed my CRW.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;tlsSupport: true&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;selfSignedCert: true&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Dealing with pod failure&lt;/h3&gt; &lt;p&gt;When you proceed with installing a new CRW instance, your pods will probably fail. To check this in the OpenShift console, go to &lt;strong&gt;Workloads&lt;/strong&gt; -&amp;#62; &lt;strong&gt;Pods&lt;/strong&gt;, then click the pod that you are interested in. As an example, you could click &lt;strong&gt;Log&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;If you prefer to use the OpenShift CLI, enter &lt;code&gt;oc get pods&lt;/code&gt;, then, &lt;code&gt;oc logs -f po/POD_NAME&lt;/code&gt;. For &lt;code&gt;POD_NAME&lt;/code&gt;, enter the pod you want to verify.&lt;/p&gt; &lt;p&gt;If you inspect the error, you will see that the image-pull event has failed with an error message: &lt;code&gt;ErrImagePull&lt;/code&gt;. In the next section, I&amp;#8217;ll show you how to fix this error by adding your OpenShift secret to the service accounts you will need to run CodeReady Workspaces in a restricted environment.&lt;/p&gt; &lt;h2&gt;Step 6: Add your OpenShift secret to new service accounts&lt;/h2&gt; &lt;p&gt;A CodeReady Workspaces deployment uses the CRW Operator to install and manage all of CRW&amp;#8217;s life-cycle processes. These processes also require leveraging various service accounts. In overview, the flow looks something like this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The &lt;code&gt;codeready-operator&lt;/code&gt; service accounts are initialized and attempt to pull the &lt;code&gt;codeready-workspaces/server-operator-rhel8&lt;/code&gt; image.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;deployer&lt;/code&gt; and &lt;code&gt;builder&lt;/code&gt; service accounts attempt to pull additional required images such as &lt;code&gt;redhat-sso-7/sso73-openshift&lt;/code&gt;, &lt;code&gt;rhscl/postgresql-96-rhel7&lt;/code&gt;, and &lt;code&gt;ubi8-minimal&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;che&lt;/code&gt; service account is created to pull the &lt;code&gt;codeready-workspaces/server-rhel8&lt;/code&gt; image.&lt;/li&gt; &lt;li&gt;Once CRW is up, the &lt;code&gt;che-workspace&lt;/code&gt; service account is used to pull in stack images for various runtimes.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;You can find the above service accounts in the OpenShift console by clicking &lt;strong&gt;Explore&lt;/strong&gt; and browsing until you find the &lt;strong&gt;ServiceAccounts&lt;/strong&gt; page, as shown in Figure 14.&lt;/p&gt; &lt;div id="attachment_658637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658637" class="size-large wp-image-658637" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount1-1024x811.jpg" alt="A screenshot of the ServiceAccounts option in the OpenShift console." width="640" height="507" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount1-1024x811.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount1-300x237.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount1-768x608.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount1.jpg 1478w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658637" class="wp-caption-text"&gt;Figure 14. Find the ServiceAccounts page in the OpenShift 4 console.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Alternatively, on the command line, you could enter &lt;code&gt;oc get sa&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Adding more service accounts&lt;/h3&gt; &lt;p&gt;The first time that you try to install CRW, you should only see the &lt;code&gt;codeready-operator&lt;/code&gt; service accounts, which are &lt;strong&gt;default&lt;/strong&gt;, &lt;strong&gt;builder&lt;/strong&gt;, and &lt;strong&gt;deployer&lt;/strong&gt;. You will have to use your OpenShift secret to add the additional service accounts. In the custom resource definition file, create a new line under &lt;code&gt;imagePullSecrets&lt;/code&gt; and add a new OpenShift secret there. Alternatively, you could override the previous OpenShift secret, as shown in Figure 15.&lt;/p&gt; &lt;div id="attachment_658647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658647" class="size-large wp-image-658647" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount3-1024x804.jpg" alt="A screenshot showing the OpenShift secret added to a new service account in the CRD file." width="640" height="503" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount3-1024x804.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount3-300x235.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount3-768x603.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount3.jpg 1203w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658647" class="wp-caption-text"&gt;Figure 15. Add your OpenShift secret to the service accounts you want to add.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Repeat this step for all of the service accounts you need for your CodeReady Workspaces deployment.&lt;/p&gt; &lt;h3&gt;Updating the deployment script&lt;/h3&gt; &lt;p&gt;Simply modifying your service accounts will not automatically trigger the changes required to deploy a CRW application in a restricted environment. You also need to modify your deployment script, as shown in Figure 16.&lt;/p&gt; &lt;div id="attachment_658657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658657" class="size-large wp-image-658657" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/success3-1024x891.jpg" alt="A screenshot of the deployment script." width="640" height="557" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/success3-1024x891.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/success3-300x261.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/success3-768x669.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658657" class="wp-caption-text"&gt;Figure 16. Modify your OpenShift deployment script to redeploy the application.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After you&amp;#8217;ve made these changes, check the pods and their logs to see whether you are able to successfully pull the images that are required for your deployment, as shown in Figure 17. Repeat the steps for any additional service accounts to pull the images that you need.&lt;/p&gt; &lt;div id="attachment_658487" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount2.jpg"&gt;&lt;img aria-describedby="caption-attachment-658487" class="wp-image-658487 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount2-1024x758.jpg" alt="A screenshot of the CodeReady Workspaces Service Accounts page." width="640" height="474" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount2-1024x758.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount2-300x222.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount2-768x569.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/serviceaccount2.jpg 1475w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-658487" class="wp-caption-text"&gt;Figure 17. View all of your pod instances in the Service Accounts page.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Step 7: Check your pods and deploy CodeReady Workspaces&lt;/h2&gt; &lt;p&gt;Once everything is up and running, you should see all of your pods are in the &lt;strong&gt;Running&lt;/strong&gt; state, as shown in Figure 18.&lt;/p&gt; &lt;div id="attachment_658677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658677" class="wp-image-658677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod1-1-1024x609.jpg" alt="A screenshot of the Running tab open on the Pods page in the OpenShift console." width="640" height="381" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod1-1-1024x609.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod1-1-300x179.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod1-1-768x457.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658677" class="wp-caption-text"&gt;Figure 18. Check the Running tab on the Pods page to find out whether your pods are successfully installed.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you notice any issues with a running pod, check for log or event errors, as shown in Figure 19.&lt;/p&gt; &lt;div id="attachment_658687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658687" class="wp-image-658687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod2-1024x704.jpg" alt="A screenshot of the OpenShift console showing log data for a running pod." width="640" height="440" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod2-1024x704.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod2-300x206.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pod2-768x528.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658687" class="wp-caption-text"&gt;Figure 19. Check for logging or event errors in your running pods.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Assuming all of your pods are running smoothly, you can now deploy your CodeReady Workspaces instance in a restricted environment, as shown in Figure 20.&lt;/p&gt; &lt;div id="attachment_658697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-658697" class="wp-image-658697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/7-1024x381.jpg" alt="A screenshot showing the Che project page and the link to deploy CodeReady Workspaces in your environment." width="640" height="238" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/7-1024x381.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/7-300x112.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/7-768x286.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-658697" class="wp-caption-text"&gt;Figure 20. The route for a successful Che deployment.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;That should be it for installing and deploying CodeReady Workspaces. You might encounter additional challenges related to working in a restricted environment.&lt;/p&gt; &lt;p&gt;For now, you should at least have CodeReady Workspaces installed and ready to use in OpenShift 4. However, that is just a start with your journey to the world of CodeReady Workspaces. In my next articles, I will cover how you can further configure CRW after installation, how to try out various development options in CRW, and how to install the monitoring solutions like Prometheus and Grafana in CRW. Until then, see you next time, and feel free to leave comments.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#38;linkname=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F12%2Fhow-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment%2F&amp;#038;title=How%20to%20install%20CodeReady%20Workspaces%20in%20a%20restricted%20OpenShift%204%20environment" data-a2a-url="https://developers.redhat.com/blog/2020/06/12/how-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment/" data-a2a-title="How to install CodeReady Workspaces in a restricted OpenShift 4 environment"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/12/how-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment/"&gt;How to install CodeReady Workspaces in a restricted OpenShift 4 environment&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/H1rPmYaIm6g" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;It&amp;#8217;s your first day as a Java programmer, right out of college. You have received your badge, a shiny new laptop, and all of your software requests have been approved. Everything seems to be going well. You install Eclipse and set up the required Java Development Kit (JDK) in your new development environment. You clone [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/12/how-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment/"&gt;How to install CodeReady Workspaces in a restricted OpenShift 4 environment&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">657467</post-id><dc:creator>Bryant Son</dc:creator><dc:date>2020-06-12T07:00:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/12/how-to-install-codeready-workspaces-in-a-restricted-openshift-4-environment/</feedburner:origLink></entry><entry><title>First look at the new Apicurio Registry UI and Operator</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/R2rhs9iezhY/" /><category term="Containers" /><category term="DevOps" /><category term="Kubernetes" /><category term="Operator" /><category term="API registry" /><category term="Apicurio" /><category term="confluent schema registry" /><category term="openshift" /><category term="schema registry" /><author><name>Hugo Guerrero</name></author><id>https://developers.redhat.com/blog/?p=727447</id><updated>2020-06-11T07:00:54Z</updated><published>2020-06-11T07:00:54Z</published><content type="html">&lt;p&gt;Last year, the &lt;a target="_blank" rel="nofollow" href="https://www.apicur.io/"&gt;Apicurio&lt;/a&gt; developer community launched the new &lt;a target="_blank" rel="nofollow" href="https://github.com/Apicurio/apicurio-registry"&gt;Apicurio Registry&lt;/a&gt; project, which is an API and schema registry for microservices. You can use the Apicurio Registry to store and retrieve service artifacts such as OpenAPI specifications and AsyncAPI definitions, as well as schemas such as Apache Avro, JSON, and Google Protocol Buffers.&lt;/p&gt; &lt;p&gt;Because the registry also works as a catalog where you can navigate through artifacts, adding a new web-based user interface (UI) was a priority for the current Apicurio Registry 1.2.2 release. With this release, the Apicurio community has made the Apicurio Registry available as a binary download or from container images. To make it easier to set up and manage your Apicurio Registry deployment, they have also created a new &lt;a target="_blank" rel="nofollow" href="https://github.com/Apicurio/apicurio-registry-operator"&gt;Kubernetes Operator for the Apicurio Registry&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article is a quick introduction to the new Apicurio Registry UI and Apicurio Registry Operator. I&amp;#8217;ll show you how to access these new features in Apicurio 1.2.2 and describe a few highlights of using them. For a more detailed demonstration, check out my video tutorial introducing the new UI and &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Operator&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-727447"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/6v4PS5vaiZc?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;The Apicurio Registry UI&lt;/h2&gt; &lt;p&gt;Apicurio&amp;#8217;s new web-based user interface allows you to navigate through artifacts stored in the Registry. You can use the UI to search for artifacts by label, name, or description. You can also preview an artifact&amp;#8217;s content, and you have the option to download and store an artifact locally. While in the registry, you can check for all of the available versions of any stored artifact.&lt;/p&gt; &lt;p&gt;In addition to browsing through artifacts, the Apicurio UI allows you to configure and manage the registry&amp;#8217;s content rules, both globally and for each artifact. Of course, it is also possible to upload new artifacts and update the content or version of any existing artifact.&lt;/p&gt; &lt;p&gt;To access the Apicurio UI, just navigate to the main endpoint of your current Apicurio Registry deployment, such as &lt;code&gt;http://localhost:8080/&lt;/code&gt;. At the endpoint, you will be redirected to the &lt;code&gt;/ui&lt;/code&gt; path.&lt;/p&gt; &lt;h2&gt;The Apicurio Registry Operator&lt;/h2&gt; &lt;p&gt;You can deploy the Apicurio Registry Operator in any working Kubernetes or OpenShift cluster, and use it to quickly install and configure an Apicurio Registry deployment. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/Apicurio/apicurio-registry-operator#quickstart"&gt;Apicurio Registry Operator deployment quickstart&lt;/a&gt; for instructions. In the future, the Operator will be available from the Kubernetes &lt;a target="_blank" rel="nofollow" href="https://operatorhub.io"&gt;operatorhub.io&lt;/a&gt; catalog.&lt;/p&gt; &lt;p&gt;After installation, you can create an ApicurioRegistry resource (see the deployment quickstart&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/Apicurio/apicurio-registry-operator/blob/master/docs/resources/example-cr/in-memory.yaml"&gt;in-memory example&lt;/a&gt;) and configure it to be deployed in your cluster. If you want to customize the deployed ApicurioRegistry resource, you can define things like the persistence type and the ingress-route configuration to expose it externally.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The Apicurio Registry and Apicurio Registry Operator make it easier to discover, manage, and work with service specifications and artifacts—not only for request-response synchronous APIs but also for asynchronous and event-driven architectures. For a &lt;a href="https://developers.redhat.com/blog/2019/12/16/getting-started-with-red-hat-integration-service-registry/"&gt;technical preview and supported version of Apicurio Registry&lt;/a&gt;, check out the &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/integration"&gt;Red Hat Integration&lt;/a&gt; service registry. This service registry is a &lt;a href="https://developers.redhat.com/blog/2019/12/17/replacing-confluent-schema-registry-with-red-hat-integration-service-registry/"&gt;drop-in replacement for the Confluent Schema Registry&lt;/a&gt; and is designed to help teams govern their service schemas.&lt;/p&gt; &lt;p&gt;Meanwhile, the Apicurio community continues enhancing Apicurio&amp;#8217;s component ecosystem. The new Apicurio Registry Operator is still in development, but we invite you to try it out and &lt;a target="_blank" rel="nofollow" href="https://github.com/Apicurio/apicurio-registry-operator"&gt;provide feedback to the team&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#38;linkname=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F11%2Ffirst-look-at-the-new-apicurio-registry-ui-and-operator%2F&amp;#038;title=First%20look%20at%20the%20new%20Apicurio%20Registry%20UI%20and%20Operator" data-a2a-url="https://developers.redhat.com/blog/2020/06/11/first-look-at-the-new-apicurio-registry-ui-and-operator/" data-a2a-title="First look at the new Apicurio Registry UI and Operator"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/11/first-look-at-the-new-apicurio-registry-ui-and-operator/"&gt;First look at the new Apicurio Registry UI and Operator&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/R2rhs9iezhY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Last year, the Apicurio developer community launched the new Apicurio Registry project, which is an API and schema registry for microservices. You can use the Apicurio Registry to store and retrieve service artifacts such as OpenAPI specifications and AsyncAPI definitions, as well as schemas such as Apache Avro, JSON, and Google Protocol Buffers. Because the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/11/first-look-at-the-new-apicurio-registry-ui-and-operator/"&gt;First look at the new Apicurio Registry UI and Operator&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">727447</post-id><dc:creator>Hugo Guerrero</dc:creator><dc:date>2020-06-11T07:00:54Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/11/first-look-at-the-new-apicurio-registry-ui-and-operator/</feedburner:origLink></entry></feed>
